---
title: "tidyGWAS"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{tidyGWAS}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Quick start

### Installation

```{r, eval = FALSE}
devtools::install_github("ararder/tidyGWAS") # install.packages("devtools")
remotes::install_github("ararder/tidyGWAS") # install.packages("remotes")
```

### Download reference files - This only has to be done once

```{r, eval = FALSE}
library(tidyGWAS)
library(fs)

# Provide filepath to a directory where you want to store reference files
ref_dir <- "path/to/storage/directory"
download_ref_files(ref_dir)

# the reference files will be stored in ref_dir/dbSNP155
dbsnp_files <- paste0(ref_dir, "/dbSNP155")
# the reference data will be stored in
```

### Provide column names tidyGWAS understands

tidyGWAS does NOT automatically parse common column names, so you need
to provide it with the correct column names. tidyGWAS_columns is a
helper function to do this. tidyGWAS uses the following naming:

CHR POS RSID EffectAllele OtherAllele EAF B SE P N CaseN ControlN N INFO
OR

```{r, eval=FALSE}
# Read in the sumstats you want to clean
# sumstats <- readr::read_tsv("path/to_sumstats/gwas.tsv.gz")
df <- tidyGWAS_columns(
  df = sumstats,
  CHR = "CHROM",
  POS = "BP",
  A1 = "Allele1"
)

cleaned <- tidyGWAS(
  # we f
  tbl = df, 
  dbsnp_path = dbsnp_files,
  # it's useful to write all the messages to a logfile, so messages are saved.
  logfile=TRUE,
  # by default, the name of the output folder is a concotonated call to Sys.time()
  # but you can adjust this by using the name argument
  name = "my_first_tidyGWAS",
  # by default, the saved file is written out as a gzipped csv file,
  # however, the arrow parquet format offers many advantages over the classical csv file
  output_format = "parquet",
  # by passing the argument outdir, you can tell tidyGWAS to copy over files
  # after a finished execution to that directory
  outdir = gwas_folder
  )


```

# In depth walk-through

Let's walk through each step more carefully, using some example files
provided in the tidyGWAS package. We will be using a version of the
sumstats from the latest GWAS on schizophrenia from the Psychiatric
Genomics Consortium
[(PGC3)](https://www.nature.com/articles/s41586-022-04434-5)

```{r}
library(tidyGWAS)
library(fs)
example_file <- tidyGWAS::test_file

```

The columns have been renamed to follow the tidyGWAS format:

```{r}
colnames(example_file)
```

```{r}
example_file |> 
  head()

```

The only mandatory argument is `tbl`. tidyGWAS accepts either a
in-memory data.frame or a filepath to tsv file. if `dbsnp_path` is not
passed, tidyGWAS cannot perform any functions relating to dbSNP, such as
repairing CHR or POS, or detecting and providing coordinate on both
genome builds.

```{r}
# here we use the example files provided in the tidyGWAS package
dbsnp_file <-  fs::path(fs::path_package("tidyGWAS"), "extdata/dbSNP155")
suppressMessages(
  cleaned <- tidyGWAS(
    tbl = example_file 
    # dbsnp_path = dbsnp_file
  )
)


```

### A more typical workflow 

Typically, you will call `tidyGWAS()` with a few more arguments than the
example above. By default `tidyGWAS()` will use `base::tempdir()` to
write to during execution. In addition, the cleaned sumstat is also
returned by the function. This means that files will NOT be saved after
you quit the R session.\
This behavior can be adjusted with the `outdir` argument, where files
will be copied to `outdir` after a successful run.

Let's take a look at how a more typical call to tidyGWAS would look:

1.  `logfile` can be set to TRUE, so the output of tidyGWAS will be
    saved in a logfile
2.  `name` The output directory can be named as a convenience.
3.  `output_format` tidyGWAS supports three output formats: 'csv',
    'parquet' or 'hivestyle'
4.  `outdir` a filepath to a directory where you want to store the
    output

```{r}
# your own sumstat
your_sumstats <- tidyGWAS::test_file

# a directory where you want your data to be stored after succesful cleaning.
# here we are using a tempdir, as an example
gwas_folder <- withr::local_tempdir()

cleaned <- tidyGWAS(
  tbl = your_sumstats, 
  dbsnp_path = dbsnp_file,
  # it's useful to write all the messages to a logfile, so messages are saved.
  logfile=TRUE,
  # by default, the name of the output folder is a concotonated call to Sys.time()
  # but you can adjust this by using the name argument
  name = "my_first_tidyGWAS",
  # by default, the saved file is written out as a gzipped csv file,
  # however, the arrow parquet format offers many advantages over the classical csv file
  output_format = "parquet",
  # by passing the argument outdir, you can tell tidyGWAS to copy over files
  # after a finished execution to that directory
  outdir = gwas_folder
  )


```

If we take a look in the output folder we provided, we can see that a
new folder has been created, called 'my_first_tidyGWAS' - the `name`
argument we passed

```{r}
list.files(gwas_folder, recursive = TRUE)
```

If we take a look at all the files inside this directory, we can see
that we a lot of files. This is to make it easy to understand what
exactly tidyGWAS has done.

Removed rows are written out, with the reason for removal in the
filename:

```         
my_first_tidyGWAS/pipeline_info/removed_rows*
```

The cleaned output:

```         
my_first_tidyGWAS/cleaned_GRCh38.parquet
```

logfile:

```         
my_first_tidyGWAS/tidyGWAS_logfile.txt" 
```

The sumstat, prior to any cleaning:

```         
"my_first_tidyGWAS/raw_sumstats.parquet"     
```

```{r}
list.files(gwas_folder, recursive = TRUE)
```

## Creating the correct column names

tidyGWAS does not automatically detect column names, but expect the
`dplyr::tibble()` to contain the correct column names.
`tidyGWAS_columns` is a helper function created to match column name to
the tidyGWAS format.

```{r}
# what if we have a file where POS was named bp, and B was named BETA?
# tidyGWAS will not recognize these as valid column names and would drop them.
wrong_colnames <- dplyr::rename(example_file, bp = POS, BETA = B)
head(wrong_colnames)

```

```{r}
# we can use tidyGWAS_columns to specify current names:
correct_names <- tidyGWAS_columns(
  # first argument is the data.frame
  tbl = wrong_colnames, 
  # then any column which is not correctly named:
  POS = "bp",
  B = "BETA"
  )
head(correct_names)


```

# Parallel computation

The Apache Arrow C++ implementation, automatically detects and uses
multiple cores. In some cases, for example when running tidyGWAS in a
HPC cluster, you might need to manually set the number of cores, which
can be done using the `OMP_NUM_THREADS` variable. This should not be a
larger number of cores than what you have requested in your HPC job (in
the example below, the "--cpus-per-task" flag)

```{bash, eval=FALSE}

#SBATCH --mem=60gb
#SBATCH --time=24:0:00
#SBATCH --cpus-per-task 8
export OMP_NUM_THREADS=8

outdir=$(pwd)
gwas=$outdir/my_gwas.tsv.gz
dbsnp_files="dbSNP155"
Rscript -e "tidyGWAS(commandArgs(trailingOnly = TRUE)[1],  dbsnp_path = commandArgs(trailingOnly = TRUE)[2],outdir = commandArgs(trailingOnly = TRUE)[3], logfile=TRUE)" $gwas $dbsnp_files $outdir

```

# Computational cost

Memory use and time scales with the size of the summary statistics. From
running tidyGWAS experimentally, here's an estimation of time and
memory.

#### CPU usage

CPU usage depends heavily on CPU type and number of available cores.

1.  Macbook Pro M2: 8 million rows, \~4.42 minutes, \< 16GB memory used
2.  AMD EPYC 75F3 32-Core Processor; \~ 6 minutes \< 16GB memory used

For 60 million rows:

1.  AMD EPYC 75F3 32-Core Processor; \~ 34 minutes \< 75gb using 5 cores

### Memory usage and number of rows

The memory usage will likely be the main constraint with increasing size
of summary statistics.

1.  20 million rows \< 20gb
2.  40 million rows \< 40gb
3.  60 million rows \< 75gb

# Reading in files from disk

Behind the scenes, tidyGWAS uses `arrow::read_delim_arrow()` to read in
the file using the filepath provided.

Through `...`, you can pass specific arguments if your file requires
adjustments to read in, such as `delim = "\t"`. You can read more about
this
[here](https://arrow.apache.org/docs/r/reference/read_delim_arrow.html).
In general, if your GWAS is in a file format that tidyGWAS struggles to
read in properly, it is often easier to read in the file using
`data.table::fread()` or `readr::read_tsv`, or any package that focus
specifically on reading in files, and then passing the data.frame to
tidyGWAS in-memory.

```{r, eval = FALSE}

file <- data.table::fread("/file/that/is/challenging_to_read.vcf.gz")
tidyGWAS(
  tbl = file,
  dbsnp_path = dbsnp_files
)

```

# download_ref_data() is not working


tidyGWAS uses a version dbSNP 155 converted to the [Apache
Arrow](https://arrow.apache.org) .parquet files. You can download the
dbSNP155 reference file from inside R using the `googledrive` package,
or by manually navigating to this
[file](https://drive.google.com/file/d/1LmgfmTQaWwJaFpBHcRQIY_kwe5iN7Pj6/view?usp=share_link)

```{r, eval = FALSE}
# You can download the file from inside R using the googledrive package:
library(googledrive)
googledrive::drive_deauth()
id <- googledrive::as_id("1LmgfmTQaWwJaFpBHcRQIY_kwe5iN7Pj6")

##### EDIT THIS:
filepath_to_store_dir <- ""
##### ---------------------

drive_download(id, path = filepath_to_store_dir)
```

The file needs to be untarred

```{bash, eval = FALSE}
# change directory to where the downloaded file is
tar -xf dbSNP155.tar dbSNP155

```
