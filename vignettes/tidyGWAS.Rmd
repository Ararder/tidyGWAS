---
title: "tidyGWAS"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{tidyGWAS}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Installation

tidyGWAS is not yet on CRAN. To install, you need to use
`devtools::install_github()` or `remotes::install_github()`

```{r, eval = FALSE}
devtools::install_github("ararder/tidyGWAS")
remotes::install_github("ararder/tidyGWAS")
```

Secondly, you will need to download the reference data. tidyGWAS uses a
slightly edited version of dbSNP v155, that is available
[here](https://zenodo.org/records/14697504).

```{bash, eval = FALSE}
wget https://zenodo.org/records/14697504/files/dbSNP155.tar
tar -xvf dbSNP155.tar

```

## Using an apptainer or docker container instead

You can skip the installation step by using a docker container with
docker or apptainer.

```{bash, eval = FALSE}
# using apptainer
apptainer pull docker://arvhar/tidygwas:latest
apptainer shell ~/tidygwas_latest.sif

# using docker 
docker run arvhar/tidygwas:latest


```

# Quick start

This is what a typical call to `tidyGWAS()` will look like. A detailed
explanation of the different arguments follows.

```{r, eval=FALSE}
# we setup a directory where we will store all summary statistics cleaned by tidyGWAS
gwas_folder <- tempfile()
# provide the filepath to the name of a directory that tidyGWAS will create.
outdir <- paste0(gwas_folder, "gwasName")

cleaned <- tidyGWAS(
  tbl = "/filepath/to/sumstats", 
  # we read in a tab-separated file, so provide tab as delimiter
  delim = "\t",
  dbsnp_path = dsnp_path,
  # 
  column_names = list(
    "CHR" = "CHROM",
    "POS" = "BP",
    "EffectAllele" = "A1",
    "B" = "Effect"
  ),
  # Number of samples are missing, so manually impute
  CaseN = 54000,
  ControlN = 73000,
  logfile=TRUE,
  output_dir = outdir
  )
```

# Tutorial

Provide tidyGWAS either with an in-memory `dplyr::tibble()` or a
filepath.

1.  Here a filepath to a gzipped tsv file is passed, along with `delim`
    = `"\t"`. tidyGWAS uses `arrow::read_delim_arrow()` to read in files
    from disk. If you have trouble with parsing the file correctly, use
    another package such as `data.table::fread()` or
    `readr::read_table()` to first read in the into memory, and then
    pass the in-memory data.frame to tidyGWAS.
2.  `dbsnp_path = dbsnp_path` gives the filepath to the reference data.
3.  `output_dir = out` gives the filepath to the output directory that
    tidyGWAS will create. The directory cannot exist yet - to protect
    for accidently overwriting files. If no argument is passed to
    `output_dir`, tidyGWAS will create a folder in the R tempdir,
    meaning that any cleaned summary statistics will deleted if the R
    session is ended.

```{r}
library(tidyGWAS)
# we use the dummy version of dbSNP that comes with the package
dbsnp_path <- system.file("extdata/dbSNP155", package = "tidyGWAS")

# a dummy sumstats with 100 000 rows
gwas <- system.file("extdata/sumstats.tsv.gz", package = "tidyGWAS")
# store the results in a temporary directory
out <- tempfile()

tidyGWAS(
  tbl = gwas,
  delim = "\t",
  dbsnp_path = dbsnp_path,
  output_dir = out
)
```

### Output files

tidyGWAS returns all its output in a directory.

```{r}
fs::dir_tree(out)
```

That's a lot of files!

1.  Removed rows are stored in `pipeline/removed_*`

2.  `metadata.yaml` contains metadata about the execution

3.  `raw` contains the summary statistics ***before*** any munging was
    done. Useful to reproduce, or to identify why rows were removed.

4.  `tidyGWAS_hivestyle` contains the cleaned summary statistics, in
    something called a [hivestyle
    partition](https://arrow.apache.org/docs/r/articles/dataset.html),
    by default. The motivation for this is detailed further
    [down](#hivestyle-partitioning) in the vignette. If you just want a
    standard csv file, use `output_format="csv"` or
    `output_format="parquet"`

5.  To read in the cleaned summary statistics:

    `df <- arrow::open_dataset(paste0(out, "/tidyGWAS_hivestyle")) |> dplyr::collect()`

### Setting column names

Almost certainly, the summary statistics you want to clean will not have
the same column name that the example file had.

```{r}
sumstats <- read.table(gwas, header=T) |> dplyr::tibble()
head(sumstats)
```

```{r}
colnames(sumstats)
```

To prevent parsing files wrong `tidyGWAS()` will not guess which columns
are which. Therefore, tidyGWAS requires the colum names to be the same
as it's native format or a mapping between tidyGWAS column names and the
column names in the input file. This is done using the `column_names`
argument, which takes a named list, where the names are the tidyGWAS
columns and the values the corresponding column in the input file.

```{r, eval = FALSE}
# what if the names were all wrong?
sumstats_with_wrong_names <- dplyr::rename(
  sumstats, 
  CHROM = CHR, 
  BP = POS,
  ID = RSID,
  A1 = EffectAllele, 
  A2 = OtherAllele,
  EFFECT = B
)

tidyGWAS(
  tbl = sumstats_with_wrong_names, 
  dbsnp_path = dbsnp_path,
  column_names = list(
    CHR = "CHROM",
    POS = "BP",
    RSID = "ID",
    EffectAllele = "A1",
    OtherAllele = "A2",
    B = "EFFECT"
  )
  )

```

### The tidyGWAS columns

tidyGWAS uses the following column names:

-   CHR

-   POS

-   RSID

-   EffectAllele

-   OtherAllele

-   EAF

-   B

-   SE

-   P

-   CaseN

-   ControlN

-   N

-   INFO

-   Z

**Note**:

If your RSID column is in the format CHR:BP:A1:A2, you can still pass it
as an RSID column.

### Inputting sample size columns

Often, the sample size column is missing from the summary statistics,
and you provide it manually. tidyGWAS has three arguments that can be
used to manually set the sample size, if it's missing from the original
file:

-   `CaseN`

-   `ControlN`

-   `N`

```{r, eval = FALSE}

cleaned <- tidyGWAS(
  tbl = sumstats, 
  dbsnp_path = dbsnp_path,
  # CaseN, ControlN and N can all be used to set sample size
  CaseN = 400,
  ControlN = 800,
  N = 1200
  )


```

### Reading in files

If you pass a filepath to tidyGWAS, it will attempt to read in the file
with `arrow::read_delim_arrow()`

The default delimiter is white space, so to read in comma-separated
files or tab-separated files, you can provide the `delim` argument to
`arrow::read_delim_arrow()` through `...`

```{r, eval=FALSE}

cleaned <- tidyGWAS(
  tbl = "filepath/to/gwas/ondisk.csv",
  # here we specify the delimiter to for csv files
  delim = ",",
  dbsnp_path = dbsnp_path,
)
```

There's a lot of different field delimiters used in the wild, and
sometimes you can struggle with inputting the correct delimiter. In such
cases, it's often much more convenient to use the effective
`data.table::fread()` or `readr::read_table()` to first read in the
summary statistics into memory before passing it to tidyGWAS.

```{r, eval=FALSE}
# use readr
sumstats <- readr::read_table("path/to/sumstats.gz.vcf")
# or data.table
sumstats <- data.table::fread("path/to/sumstats.gz.vcf")

output <- "my_gwas_dir"

cleaned <- tidyGWAS(
  tbl = sumstats,
  dbsnp_path = dbsnp_path,
  outdir = output
)

```

# Hivestyle-partitioning {#hivestyle-partitioning}

The default output format is a hivestyle format using .parquet files.
See for example
[here](https://arrow.apache.org/docs/r/articles/dataset.html) for some
motivation for this. In essence, this format will significantly speed up
other downstream applications such as meta-analysis, LD querying and
other analyses.

### Variant identity

TidyGWAS will add the following columns dealing with variant ID, in
addition to saving and validating all valid columns in the input file.

1.  `CHR` Chromosome. The same across both builds

2.  `POS_38`, `POS_37` genomic position on GRCh38 and GRCh37

3.  `RSID` variant ID from dbSNP

4.  `REF_37`, `REF_38` is the reference genome allele on GRCh38 and
    GRCh37

5.  `multi_allelic` is a TRUE/FALSE column that flag rows that were
    multi-allelic IN the summary statistics NOT whether there are
    multiple alleles in dbSNP. (TRUE corresponds to multi allelic).

6.  `rowid` maps each row back to the inputted summary statistics the
    file in `raw`, so that any row can be mapped back to it's original
    values.

7.  `indel` TRUE/FALSE whether the variant is of type INsertion/DELetion

8.  All other valid columns in the input summary statistics file

9. If possible `repair_stats()` will add statistics columns such as
    `B, P, SE, Z`, if they are missing and possible to repair.

# Parallel computation

tidyGWAS automatically detects the number of cores. In some cases, for
example when running tidyGWAS in a HPC cluster, you might need to
manually set the number of cores, which can be done using the
`OMP_NUM_THREADS` variable. This should not be a larger number of cores
than what you have requested in your HPC job (in the example below, the
"--cpus-per-task" flag)

```{bash, eval=FALSE}

#SBATCH --mem=60gb
#SBATCH --time=24:0:00
#SBATCH --cpus-per-task 8
export OMP_NUM_THREADS=8

outdir=$(pwd)
gwas=$outdir/my_gwas.tsv.gz
dbsnp_files="dbSNP155"
Rscript -e "tidyGWAS(commandArgs(trailingOnly = TRUE)[1],  dbsnp_path = commandArgs(trailingOnly = TRUE)[2],outdir = commandArgs(trailingOnly = TRUE)[3], logfile=TRUE)" $gwas $dbsnp_files $outdir

```

# Computational cost and memory usage

Memory use and time scales with the size of the summary statistics. From
running tidyGWAS, here's an estimation. Especially, if the summary statistics are
missing CHR and POS, tidyGWAS will require additional memory.
1.  10 million rows ~ 5-15gb
2.  40 million rows 10-40gb
3.  60 million rows 65-85gb

