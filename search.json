[{"path":"http://arvidharder.com/tidyGWAS/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 tidyGWAS authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"tidyGWAS","text":"","code":"devtools::install_github(\"ararder/tidyGWAS\") # install.packages(\"devtools\") remotes::install_github(\"ararder/tidyGWAS\") # install.packages(\"remotes\")"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"download-reference-files","dir":"Articles","previous_headings":"","what":"Download reference files","title":"tidyGWAS","text":"tidyGWAS uses reference data dbSNP, transformed parquet files. can downloaded . file needs untarred can used.","code":"# zenodo link wget -O dbSNP155.tar https://zenodo.org/records/11060095/files/dbSNP155.tar tar -xvf dbSNP155.tar # remove the tarred dir rm dbSNP155.tar"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"quick-start","dir":"Articles","previous_headings":"","what":"Quick start","title":"tidyGWAS","text":"tidyGWAS two mandatory arguments: tbl: -memory data.frame file path summary statistics dbsnp_path: file path dbSNP reference file argument mandatory useful output_dir. tidyGWAS outputs files execution directory, filepath provided output_dir path tidyGWAS create output folder. folder exist yet (prevent accidental overwriting files). example , new directory called scz_testfile created inside /home/cleaned_tidyGWAS. output_diris set, tidyGWAS create folder inside R tempdir.","code":"# here we use an in-memory data frame that comes with the tidyGWAS package sumstats <- tidyGWAS::test_file output_dir <- \"path/to/tidyGWAS_files/<trait_name>\" cleaned <- tidyGWAS(   # Here we input the summary statistics as a data.frame already in R memory   tbl = sumstats,    # provide the filepath to the refence files you downloaded.   dbsnp_path = fs::path(fs::path_package(\"tidyGWAS\"), \"extdata/dbSNP155\"),   output_dir = \"/home/cleaned_tidyGWAS/scz_testfile\"   )"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"columnar-names","dir":"Articles","previous_headings":"Quick start","what":"Columnar names","title":"tidyGWAS","text":"vast majority cases, column names input summary statistics different nomenclature tidyGWAS uses. case use column_names argument, takes list input. list names correspond tidyGWAS nomenclature, values column name summary statistics file want clean.","code":"# First we create a list # list names = tidyGWAS names # list values = input names  col_names <- list(   \"CHR\" = \"chrom\",   \"EffectAllele\" = \"A1\",   \"EAF\" = \"AlleleFreq\" ) sumstats <- tidyGWAS::test_file  cleaned <- tidyGWAS(   tbl = sumstats,    # provide the filepath to the refence files you downloaded   dbsnp_path = fs::path(fs::path_package(\"tidyGWAS\"), \"extdata/dbSNP155\"),      column_names = col_names   )"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"the-tidygwas-nomenclature","dir":"Articles","previous_headings":"Quick start","what":"The tidyGWAS nomenclature","title":"tidyGWAS","text":"tidyGWAS uses following column names: CHR POS RSID EffectAllele OtherAllele EAF B SE P CaseN ControlN N INFO Z Note: RSID column format CHR:BP:A1:A2, can still pass RSID column.","code":""},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"reading-files-directly-from-disk","dir":"Articles","previous_headings":"Quick start","what":"Reading files directly from disk","title":"tidyGWAS","text":"pass filepath tidyGWAS, attempt read file arrow::read_delim_arrow() default delimiter white space, read comma-separated files tab-separated files, can use ... provide delim argument arrow::read_delim_arrow(). ’s lot different field delimiters used wild, sometimes can struggle inputting correct delimiter. cases, ’s often much convenient use effective data.table::fread() readr::read_table() first read summary statistics memory passing tidyGWAS.","code":"library(readr) tmp_filepath <- tempfile() # write a tsv file to disk write_tsv(tidyGWAS::test_file, tmp_filepath)  # Here we need to provide the delim argument cleaned <- tidyGWAS(   tbl = tmp_filepath,   # here we specify the delimiter   delim = \"\\t\",   dbsnp_path = fs::path(fs::path_package(\"tidyGWAS\"), \"extdata/dbSNP155\"), ) library(data.table)  # write a tsv file to disk sumstats <- fread(\"path/to/sumstats.gz.vcf\")  # Here we need to provide the delim argument cleaned <- tidyGWAS(   tbl = tmp_filepath,   # here we specify the delimiter   delim = \"\\t\",   dbsnp_path = fs::path(fs::path_package(\"tidyGWAS\"), \"extdata/dbSNP155\"),   # here we specify the output directory, and use scz2022 as name for the output directory   outdir = \"output_dir/scz2022\" )"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"inputting-sample-size-columns","dir":"Articles","previous_headings":"Quick start","what":"Inputting sample size columns","title":"tidyGWAS","text":"’s uncommon sample size also missing summary statistics. can passed similar manner column names. tidyGWAS three arguments can used manually set sample size, ’s missing original file: CaseN ControlN N","code":"colmap <- list(   \"CHR\" = \"chrom\",   \"EffectAllele\" = \"A1\",   \"EAF\" = \"AlleleFreq\" )   cleaned <- tidyGWAS(   tbl = wrong_names,    dbsnp_path = fs::path(fs::path_package(\"tidyGWAS\"), \"extdata/dbSNP155\"),   column_names = colmap,   # now we add the sample_size arguments   CaseN = 400, # we can set    ControlN = 800,   N = 1200   )"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"a-typical-tidygwas-call","dir":"Articles","previous_headings":"","what":"A typical tidyGWAS call","title":"tidyGWAS","text":"cases, three first arguments used. Let’s walk step carefully, using example files provided tidyGWAS package. using version sumstats latest GWAS schizophrenia Psychiatric Genomics Consortium (PGC3) Change column names simulate typically happen. call tidyGWAS, need provide correct column names. default, tidyGWAS produces hivestyle parquet files, prefer classical ‘csv’ file, can use output_format argument.","code":"library(tidyGWAS) library(fs)  example_sumstats <- tidyGWAS::test_file # here we use the example files provided in the tidyGWAS package example_ref_file <-  fs::path(fs::path_package(\"tidyGWAS\"), \"extdata/dbSNP155\")  #The columns have been renamed to follow the tidyGWAS format: colnames(example_sumstats) example_sumstats <- example_sumstats |>    dplyr::rename(   CHROM = CHR, BP = POS, A1 = EffectAllele, Effect=B ) |>  dplyr::select(-CaseN, -ControlN) # we setup a directory where we will store our tidyGWAS output gwas_folder <- tempfile()  cleaned <- tidyGWAS(   # provide the filepath to my summary statistics, (on disk)   tbl = example_sumstats,    # we need to provide the file delimiter   delim = \",\",   # filepath to the reference files you downloaded previously   dbsnp_path = example_ref_file,   # we input the column names of the input file that do not correspond to tidyGWAS   column_names = list(     \"CHR\" = \"CHROM\",     \"POS\" = \"BP\",     \"EffectAllele\" = \"A1\",     \"B\" = \"Effect\"   ),   # This is the default argument, but you can change to 'csv' or 'parquet'   # to output a csv file or a .parquet file   output_format = \"hivestyle\",   # sample sizes were missing, so we need to provide it also   CaseN = 54000,   ControlN = 73000,   # output_format can be adjusted.    # ouput_format = \"csv\"   # it's useful to write all the messages to a logfile, so messages are saved.   logfile=TRUE,   # i want the output folder to be named after which GWAS it was.    output_dir = paste0(gwas_folder, \"/scz_pgc3\")   )"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"the-files-produced-by-tidygwas","dir":"Articles","previous_headings":"","what":"The files produced by tidyGWAS","title":"tidyGWAS","text":"folder specified output_dir, following files: metadata.yaml record arguments passed. Useful reproducing results. pipeline_info/* contain set files corresponding removed rows. raw/* prior cleaning, raw summary statistics saved without edits. tidyGWAS_hivestyle used default output_format, folder exist contain cleaned summary statistics hivestyle partitioned format .parquet files. tidyGWAS_logfile.txt used logfile=TRUE, log saved ","code":"dir_tree(gwas_folder, recurse = 1)"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"hivestyle-partitioning-format","dir":"Articles","previous_headings":"The files produced by tidyGWAS","what":"Hivestyle partitioning format","title":"tidyGWAS","text":"default output format hivestyle format using .parquet files. See example motivation . essence, format significantly speed downstream applications meta-analysis, LD querying analyses.","code":"dir_tree(fs::path(gwas_folder,\"scz_pgc3\", \"tidyGWAS_hivestyle\"), recurse =2)  # This is the equivalent of readr::read_tsv() or data.table::fread() for  # the hivestyle format."},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"the-output-format","dir":"Articles","previous_headings":"","what":"The output format","title":"tidyGWAS","text":"partitioned .parquet files can easily read memory using arrow::open_dataset() |> collect(). tidyGWAS() add set columns, depending existed input columns. possible, statistics columns B, P, SE, Z added missing possible impute . POS, CHR correspond GRCh38 POS_37, CHR_37 correspond GRCh37. always exist, regardless initial build, unless add_missing_build = FALSE. multi_allelic TRUE/FALSE column flag rows multi-allelic summary statistics whether multiple alleles dbSNP. (TRUE corresponds multi_allelic). rowid maps row back inputted summary statistics, row can mapped back ’s original values. REF reference genome allele whichever build summary statistics initially . ID concatenation CHR:POS:EffectAllele:OtherAllele, EffectAllele always correspond REF. OBS!! B EAF flipped, use ID correctly first need flip B EAF. indel TRUE/FALSE columns flags insertions deletions. TRUE rows indels. missing unlesss indels detected. remaining columns tidyGWAS nomenclature standard GWAS columns","code":"df <- arrow::open_dataset(fs::path(gwas_folder,\"scz_pgc3\", \"tidyGWAS_hivestyle\")) |>    dplyr::collect()  df <- arrow::open_dataset(fs::path(gwas_folder,\"scz_pgc3\", \"tidyGWAS_hivestyle\")) |>    # note: when working interactively, remember to select a subset of columns. This will result in much quicker IO.   # dplyr::select(-dplyr::any_of(c(\"CHR_37\", \"POS_37\",\"rowid\", \"multi_allelic\", \"indel\", \"REF\")))   dplyr::collect() colnames(df)"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"parallel-computation","dir":"Articles","previous_headings":"","what":"Parallel computation","title":"tidyGWAS","text":"tidyGWAS automatically detects number cores, uses parallelize alignment dbSNP. cases, example running tidyGWAS HPC cluster, might need manually set number cores, can done using OMP_NUM_THREADS variable. larger number cores requested HPC job (example , “–cpus-per-task” flag)","code":"#SBATCH --mem=60gb #SBATCH --time=24:0:00 #SBATCH --cpus-per-task 8 export OMP_NUM_THREADS=8  outdir=$(pwd) gwas=$outdir/my_gwas.tsv.gz dbsnp_files=\"dbSNP155\" Rscript -e \"tidyGWAS(commandArgs(trailingOnly = TRUE)[1],  dbsnp_path = commandArgs(trailingOnly = TRUE)[2],outdir = commandArgs(trailingOnly = TRUE)[3], logfile=TRUE)\" $gwas $dbsnp_files $outdir"},{"path":"http://arvidharder.com/tidyGWAS/articles/tidyGWAS.html","id":"computational-cost","dir":"Articles","previous_headings":"","what":"Computational cost","title":"tidyGWAS","text":"Memory use time scales size summary statistics. running tidyGWAS experimentally, ’s estimation: memory usage likely main constraint increasing size summary statistics. 20 million rows ~20gb 40 million rows ~40gb 60 million rows ~75gb","code":""},{"path":[]},{"path":"http://arvidharder.com/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"converting-dbsnp-to--parquet-files","dir":"Articles","previous_headings":"","what":"Converting dbSNP to .parquet files","title":"get-to-know-dbsnp","text":"dbSNP data accessed munged BSgenome package. Takes 10~30 minutes per chromosome, peak memory usage ~80gb chromosome 2","code":"library(arrow) library(BSgenome) library(glue)  chr <- commandArgs(trailingOnly = TRUE)[1] build <- commandArgs(trailingOnly = TRUE)[2]  if(build == \"37\") {   snps <- SNPlocs.Hsapiens.dbSNP155.GRCh37::SNPlocs.Hsapiens.dbSNP155.GRCh37   genome <- BSgenome.Hsapiens.1000genomes.hs37d5::BSgenome.Hsapiens.1000genomes.hs37d5   grch <- \"GRCh37\" } else if(build == \"38\") {    snps <- SNPlocs.Hsapiens.dbSNP155.GRCh38::SNPlocs.Hsapiens.dbSNP155.GRCh38   genome <- BSgenome.Hsapiens.NCBI.GRCh38::BSgenome.Hsapiens.NCBI.GRCh38   grch <- \"GRCh38\" } outpath <- glue(\"~/arvhar/snp_level_annotatations/dbSNP155/{grch}\")  # IUPAC ambuigity codes, to update FASTA files from ref genome updated <-   stringr::str_split(Biostrings::IUPAC_CODE_MAP, \"\") |>   purrr::map(\\(x) stringr::str_flatten(x, collapse=\",\")) |>   purrr::map_chr(stringr::str_c) |>   purrr::set_names(names(Biostrings::IUPAC_CODE_MAP))    print(glue(\"converting data for chr {chr}\"))  tictoc::tic(glue::glue(\"finished reading in chr: {chr}\")) all_snps <- snpsBySeqname(snps, seqnames = chr, genome = genome, drop.rs.prefix=TRUE) tictoc::toc()   dt <- data.table::as.data.table(all_snps) dt <- dplyr::mutate(dt, ref_allele = updated[ref_allele], alt_alleles = updated[alt_alleles]) dt <- tidyr::separate_longer_delim(dt, ref_allele, delim =\",\")  dt <- dplyr::select(dt, CHR = seqnames, POS =pos, RSID = RefSNP_id, REF = ref_allele, ALT = alt_alleles)  # storing as integer speeds up computation later on dt <- dplyr::mutate(dt, RSID = as.integer(stringr::str_sub(start = 3, RSID)))  print(glue(\"Writing data to {outpath}\")) write_dataset(dplyr::group_by(dt, CHR), outpath)"},{"path":"http://arvidharder.com/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"pruning-duplicates","dir":"Articles","previous_headings":"","what":"Pruning duplicates","title":"get-to-know-dbsnp","text":"","code":"remove_dups <- function(kk) {     start <- nrow(kk)      step1 <- distinct(kk, .keep_all=TRUE)     n_step1 <- nrow(step1)     cli::cli_alert(\"removed {start-n_step1} rows as pure duplicates\")      step2 <- mutate(step1, dup_rsid = duplicated(step1[,\"RSID\"]) | duplicated(step1[,\"RSID\"], fromLast = TRUE)) |>          filter(!dup_rsid)     step2$dup_rsid <- NULL     n_step2 <- nrow(step2)     cli::cli_alert(\"removed {n_step1-n_step2} rows with duplicated RSIDs\")       step3 <- distinct(arrange(step2, RSID), CHR, POS, .keep_all=TRUE)     n_step3 <- nrow(step3)     cli::cli_alert(\"removed {n_step2 - n_step3} rows with duplicated CHR-POS\")      cli::cli_alert_warning(\"removed a total of {start - n_step3} rows\")     step3     }  clean_dbsnp <- function(chr) {     tictoc::tic(glue::glue(\"time to clean {chr}\"))     df1 <- arrow::open_dataset(\"~/ki-pgi-storage/Data/downstreamGWAS/reference/dbSNP155/GRCh37\") |>          filter(CHR == chr) |>          dplyr::collect()      df1 <- remove_dups(df1)     n_df1 <- nrow(df1)      df2 <- arrow::open_dataset(\"~/ki-pgi-storage/Data/downstreamGWAS/reference/dbSNP155/GRCh38\") |>          filter(CHR == chr) |>          dplyr::collect()      df2 <- remove_dups(df2)     n_df2 <- nrow(df2)           ###################### MERGE ######################     out <- inner_join(df1, df2, by = \"RSID\", suffix = c(\"_37\", \"_38\"))          cli::cli_alert(\"removed {n_df2 - nrow(out)} rows from GRCh38, and {n_df1 - nrow(out)} from GRCH37 after merging across genome builds\")      final <- filter(out, CHR_37 == CHR_38) |>          rename(CHR = CHR_38)          cli::cli_alert(\"removed {nrow(out) - nrow(final)} rows with different chromosome numbers across genonme builds\")          final |>          select(-CHR_37) |>          relocate(CHR, POS_38, POS_37, RSID, REF_38, REF_37, ALT_38, ALT_37) |>          group_by(CHR) |>          arrow::write_dataset(\"dbSNP155_v2\")      tictoc::toc() }    tr <- c(1:22, \"X\", \"Y\", \"MT\") withr::local_message_sink(\"logfile.txt\") for(x in tr) {     clean_dbsnp(x) }"},{"path":"http://arvidharder.com/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"transforming-refsnp-merged-to-parquet","dir":"Articles","previous_headings":"Pruning duplicates","what":"Transforming refsnp-merged to parquet","title":"get-to-know-dbsnp","text":"","code":"library(arrow) library(tidyverse)  # wget https://ftp.ncbi.nlm.nih.gov/snp/latest_release/JSON/refsnp-merged.json.bz2 ref <- read_json_arrow(\"~/refsnp-merged.json.bz2\", col_select = c(\"refsnp_id\", \"merged_snapshot_data\"))  RSID = ref$merged_snapshot_data$merged_into test <- map_chr(ref$merged_snapshot_data$merged_into, \\(x) stringr::str_flatten(x))  old_RSID = ref$refsnp_id tmp = data.frame(old_RSID, test) tmp$old_RSID = as.integer(tmp$old_RSID) tmp$test = as.integer(tmp$test)   write_parquet(tmp, \"~/part0\", compression = \"gzip\")  # write out as parquet"},{"path":"http://arvidharder.com/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"noteworthy-aspects-of-dbsnp155","dir":"Articles","previous_headings":"","what":"Noteworthy aspects of dbSNP155","title":"get-to-know-dbsnp","text":"dbSNP version: 155 section work progress, summarises idiosyncracies dbSNP data.","code":""},{"path":"http://arvidharder.com/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"issue-1---same-chrpos-can-map-to-multiple-snps","dir":"Articles","previous_headings":"Noteworthy aspects of dbSNP155","what":"Issue 1) - same CHR:POS can map to multiple SNPs","title":"get-to-know-dbsnp","text":"particular example, three SNPs merged rs10157617. check history tab however, can see merge happened dbSNP 156. - issue yet fixed data tidyGWAS using.","code":""},{"path":"http://arvidharder.com/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"solution","dir":"Articles","previous_headings":"Noteworthy aspects of dbSNP155 > Issue 1) - same CHR:POS can map to multiple SNPs","what":"Solution","title":"get-to-know-dbsnp","text":"case CHR:POS maps multiple RSIDs, tidyGWAS selects RSID smallest rs number, mimic dbSNP performs merges.","code":"# on GRCh38 #  CHR        POS RSID         ref_allele alt_alleles #   <chr>    <int> <chr>        <chr>      <list>      # 1 1     39491595 rs10157617   T          <chr [2]>   # 2 1     39491595 rs1638449573 T          <chr [1]>   # 3 1     39491595 rs1638449625 T          <chr [1]>   # 4 1     39491595 rs1638449683 T          <chr [1]>"},{"path":"http://arvidharder.com/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"some-snps-only-have-chrpos-on-grch37","dir":"Articles","previous_headings":"Noteworthy aspects of dbSNP155 > Issue 1) - same CHR:POS can map to multiple SNPs","what":"2) Some SNPs only have CHR:POS on GRCh37","title":"get-to-know-dbsnp","text":"SNPs CHR POS GRCh37, yet mapped GRCh38. tidyGWAS() simply show rows CHR POS missing, CHR_37 POS_37 !","code":""},{"path":"http://arvidharder.com/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"some-rsids-map-to-multiple-chrpos","dir":"Articles","previous_headings":"Noteworthy aspects of dbSNP155 > Issue 1) - same CHR:POS can map to multiple SNPs","what":"3) some RSIDs map to multiple CHR:POS","title":"get-to-know-dbsnp","text":"See NCBI discussion","code":""},{"path":"http://arvidharder.com/tidyGWAS/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Arvid Harder. Maintainer.","code":""},{"path":"http://arvidharder.com/tidyGWAS/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Harder (2024). tidyGWAS: Quality control GWAS summary statistics minimal filtering. R package version 0.9.0, http://arvidharder.com/tidyGWAS/.","code":"@Manual{,   title = {tidyGWAS: Quality control for GWAS summary statistics with minimal filtering},   author = {Arvid Harder},   year = {2024},   note = {R package version 0.9.0},   url = {http://arvidharder.com/tidyGWAS/}, }"},{"path":"http://arvidharder.com/tidyGWAS/index.html","id":"tidygwas","dir":"","previous_headings":"","what":"Quality control for GWAS summary statistics with minimal filtering","title":"Quality control for GWAS summary statistics with minimal filtering","text":"Genome-wide summary statistics becoming staple many different genetics genomics analysis pipelines. Often, specific filters suggested pipelines can different, requiring pipeline step summary statistics “munged”. tidyGWAS aims provide standardized format pipeline specific munging done. mind, tidyGWAS conservative removing rows, default keeps indels multi-allelic variants. tidyGWAS following: Detection duplicated rows (based RSID_REF_ALT CHR_POS_REF_ALT) Standardized column names Automatic updating merged RSIDs Detection optional removal deletions/insertions (“indels”) Detection non rsID values RSID column, automatic parsing common CHR:POS CHR:POS:REF:ALT format Standardization CHR values (ex: “23” -> “X”, “chr1” -> “1”) Validation standard GWAS columns, B, SE, P, N, FREQ, Z, CaseN, ControlN, A1, A2 Extremely small pvalues default converted 2.225074e-308 (minimum pvalue R) Imputation missing columns: RSID CHR:POS CHR:POS RSID. B,SE, P, Z missing possible Validation CHR:POS:RSID matching dbSNP v.155 Cleaned sumstats provided coordinates GRCh37 GRCh38, TRUE/FALSE flags indels variants multi-allelic dataset working standardized GWAS formats, ’ve found GRCh37 GRCh38 coordinates, standardized column names significantly speeds downstream analysis. computationally intensive part aligning summary statistics dbSNP 155 (> 940 million rows) GRCh37 GRCh38 (total 1.8 billion rows) implemented using Apache Arrow R implementation, allowing full function run <5 minutes, using less 16gb, ~7 million rows Macbook Pro M2.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/detect_indels.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Insertions/Deletions ('indels') — detect_indels","title":"Detect Insertions/Deletions ('indels') — detect_indels","text":"Indels detected examining EffectAllele OtherAllele","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/detect_indels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Insertions/Deletions ('indels') — detect_indels","text":"","code":"detect_indels(tbl, indel_strategy, filepaths, ...)"},{"path":"http://arvidharder.com/tidyGWAS/reference/detect_indels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Insertions/Deletions ('indels') — detect_indels","text":"tbl dplyr::tibble() indel_strategy indels kept removed? filepaths list filepaths, created setup_pipeline_paths() ... pass additional arguments arrow::read_delim_arrow(), tbl filepath.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/detect_indels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Insertions/Deletions ('indels') — detect_indels","text":"tbl","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/detect_indels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect Insertions/Deletions ('indels') — detect_indels","text":"","code":"if (FALSE) { # \\dontrun{ detect_indels(sumstat, TRUE, filepaths = setup_pipeline_paths(\"testing\")) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_duplicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Find all rows which are part of a set of duplicated rows — flag_duplicates","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"Many duplication tools base::duplicated() dplyr::distinct() identify rows duplications. often useful see rows part duplication set, just second row. creates new column: dup_rsid dup_chr_pos, T/F flag. Specifically, flags rows duplication pair, just first last duplicate row, making easy work rows part duplication","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_duplicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"","code":"flag_duplicates(   tbl,   column = c(\"rsid\", \"chr_pos\", \"chr_pos_ref_alt\", \"rsid_ref_alt\") )"},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_duplicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"tbl dplyr::tibble() column columns used form unique ID?","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_duplicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"tibble new columns dup_column","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_duplicates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"","code":"if (FALSE) { # \\dontrun{  # will tag multi-allelics as duplications flag_duplicates(tbl, column = \"rsid\") flag_duplicates(tbl, column = \"chr_pos\") # if you are interested in rows that are variant duplications flag_duplicates(tbl, column = \"rsid_ref_alt\") flag_duplicates(tbl, column = \"chr_pos_ref_alt\")  } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_indels.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect ","title":"Detect ","text":"Detect \"indels\" GWAS summary statistics","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_indels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect ","text":"","code":"flag_indels(tbl)"},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_indels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect ","text":"tbl dplyr::tibble() columns EffectAllele OtherAllele","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_indels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect ","text":"dplyr::tibble() TRUE/FALSE column indel added, indel == TRUE corresponds row marked indel.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_indels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect ","text":"","code":"if (FALSE) { # \\dontrun{ all_indels <-   flag_indels(tbl) |>   dplyr::filter(indels) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_invalid_rsid.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"Detect entries valid rsID's GWAS summary statistics","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_invalid_rsid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"","code":"flag_invalid_rsid(tbl, regex = \"^[rR][sS]?\\\\d{1,10}$\")"},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_invalid_rsid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"tbl dplyr::tibble() column RSID. regex regex used detect non-RSIDs","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_invalid_rsid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"dplyr::tibble() column invalid_rsid","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/flag_invalid_rsid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"","code":"if (FALSE) { # \\dontrun{ flag_invalid_rsid(tbl) |> dplyr::filter(invalid_rsid) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/infer_build.html","id":null,"dir":"Reference","previous_headings":"","what":"Infer what genome build a GWAS summary statistics file is on. — infer_build","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"Infer genome build GWAS summary statistics file .","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/infer_build.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"","code":"infer_build(tbl, dbsnp_path, n_snps = 10000)"},{"path":"http://arvidharder.com/tidyGWAS/reference/infer_build.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"tbl data.frame character() vector dbsnp_path filepath dbSNP155 directory (untarred dbSNP155.tar) n_snps number snps check CHR POS ","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/infer_build.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"either \"37\" \"38\"","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/infer_build.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"","code":"if (FALSE) { # \\dontrun{ genome_build <- infer_build(gwas_sumstats) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_duplicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove duplicated rows — remove_duplicates","title":"Remove duplicated rows — remove_duplicates","text":"remove_duplicates uses either CHR:POS:EffectAllele:OtherAllele RSID:EffectAllele:OtherAllele compute uniqueness. possible rows arranged p-value, select row smallest P.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_duplicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove duplicated rows — remove_duplicates","text":"","code":"remove_duplicates(tbl, filepaths)"},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_duplicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove duplicated rows — remove_duplicates","text":"tbl dplyr::tibble() filepaths list filepaths, created setup_pipeline_paths()","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_duplicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove duplicated rows — remove_duplicates","text":"tbl","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_duplicates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove duplicated rows — remove_duplicates","text":"","code":"if (FALSE) { # \\dontrun{ paths <- setup_pipeline_paths(\"testing\") df <- remove_duplicates(sumstat, paths) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_rows_with_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove rows with missing values, and write out the removed files to disk — remove_rows_with_na","title":"Remove rows with missing values, and write out the removed files to disk — remove_rows_with_na","text":"Remove rows missing values, write removed files disk","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_rows_with_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove rows with missing values, and write out the removed files to disk — remove_rows_with_na","text":"","code":"remove_rows_with_na(tbl, filepaths)"},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_rows_with_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove rows with missing values, and write out the removed files to disk — remove_rows_with_na","text":"tbl dplyr::tibble() filepaths list filepaths, created setup_pipeline_paths()","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_rows_with_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove rows with missing values, and write out the removed files to disk — remove_rows_with_na","text":"tbl","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/remove_rows_with_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove rows with missing values, and write out the removed files to disk — remove_rows_with_na","text":"","code":"if (FALSE) { # \\dontrun{ df <- remove_rows_with_na(sumstat, setup_pipeline_paths(\"testing\")) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/repair_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"repair_stats() collection functions can used infer missing columns GWAS summary statistics. functions based functionality found online.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/repair_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"","code":"repair_stats(tbl)"},{"path":"http://arvidharder.com/tidyGWAS/reference/repair_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"tbl data.frame character() vector","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/repair_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"tibble","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/repair_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"","code":"if (FALSE) { # \\dontrun{ updated <- repair_stats(my_gwas) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/select_correct_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove all columns that do not follow tidyGWAS naming — select_correct_columns","title":"Remove all columns that do not follow tidyGWAS naming — select_correct_columns","text":"Remove columns follow tidyGWAS naming","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/select_correct_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove all columns that do not follow tidyGWAS naming — select_correct_columns","text":"","code":"select_correct_columns(tbl)"},{"path":"http://arvidharder.com/tidyGWAS/reference/select_correct_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove all columns that do not follow tidyGWAS naming — select_correct_columns","text":"tbl dplyr::tibble()","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/select_correct_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove all columns that do not follow tidyGWAS naming — select_correct_columns","text":"dplyr::tibble()","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/select_correct_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove all columns that do not follow tidyGWAS naming — select_correct_columns","text":"","code":"if (FALSE) { # \\dontrun{ sumstats <- select_correct_columns(sumstats) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/setup_pipeline_paths.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the folder structure for tidyGWAS — setup_pipeline_paths","title":"Create the folder structure for tidyGWAS — setup_pipeline_paths","text":"Create folder structure tidyGWAS","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/setup_pipeline_paths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the folder structure for tidyGWAS — setup_pipeline_paths","text":"","code":"setup_pipeline_paths(outdir, filename)"},{"path":"http://arvidharder.com/tidyGWAS/reference/setup_pipeline_paths.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the folder structure for tidyGWAS — setup_pipeline_paths","text":"outdir output directory filename filename raw sumstats","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/setup_pipeline_paths.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the folder structure for tidyGWAS — setup_pipeline_paths","text":"list filepaths","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/setup_pipeline_paths.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the folder structure for tidyGWAS — setup_pipeline_paths","text":"","code":"setup_pipeline_paths(tempfile()) #> $base #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819\" #>  #> $logfile #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/tidyGWAS_logfile.txt\" #>  #> $cleaned #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/tidyGWAS_hivestyle\" #>  #> $raw_sumstats #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/raw/raw.parquet\" #>  #> $metadata #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/metadata.yaml\" #>  #> $updated_rsid #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/updated_rsid.parquet\" #>  #> $removed_rows #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_\" #>  #> $removed_duplicates #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_duplicates.parquet\" #>  #> $failed_rsid_parse #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_failed_rsid_parse.parquet\" #>  #> $removed_invalid_chr_pos_in_rsid #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_invalid_chr_pos_rsid.parquet\" #>  #> $removed_indels #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_indels.parquet\" #>  #> $removed_validate_rsid #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_validate_rsid_path.parquet\" #>  #> $removed_validate_rsid_without_rsid #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_without_rsid.parquet\" #>  #> $removed_validate_chr_pos #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_validate_chr_pos_path.parquet\" #>  #> $removed_validate_indels #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_validate_indels.parquet\" #>  #> $removed_duplications_chr_pos_in_rsid_col #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_duplications_chr_pos_in_rsid_col.parquet\" #>  #> $removed_no_dbsnp #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_nodbsnp.parquet\" #>  #> $removed_chr_mismatch #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_chr_mismatch.parquet\" #>  #> $removed_missing_on_either_build #> [1] \"/tmp/RtmpahzQYe/file16fb5389c819/pipeline_info/removed_missing_on_either_build.parquet\" #>"},{"path":"http://arvidharder.com/tidyGWAS/reference/tidyGWAS.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"tidyGWAS() performs set validations input colummns, repairs missing columns, can add missing CHR/POS RSID. addition, CHR POS standardised GRCh38, coordinates GRCh37 added well. Briefly, tidyGWAS() updates RSID possible using refsnp-merged file dbSNP. inputed column validated coerced correct type. statistis P, B missing, tidyGWAS() attempt impute possible using repair_stats() Standard column names assumed, inputting function. deliberate decision automatic parsing important column names can ambiguous example, sumstats, A1 referes effect allele, formats use A1 non-effect allele.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/tidyGWAS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"","code":"tidyGWAS(   tbl,   dbsnp_path,   ...,   column_names,   output_format = c(\"hivestyle\", \"parquet\", \"csv\"),   output_dir = paste0(tempdir(), \"/\", stringr::str_replace_all(date(), pattern = c(` ` =     \"_\", `:` = \"_\"))),   CaseN = NULL,   ControlN = NULL,   N = NULL,   build = c(\"NA\", \"37\", \"38\"),   default_build = c(\"37\", \"38\"),   indel_strategy = c(\"keep\", \"remove\"),   convert_p = 2.225074e-308,   repair_cols = TRUE,   logfile = FALSE )"},{"path":"http://arvidharder.com/tidyGWAS/reference/tidyGWAS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"tbl data.frame character() vector dbsnp_path filepath dbSNP155 directory (untarred dbSNP155.tar) ... pass additional arguments arrow::read_delim_arrow(), tbl filepath. column_names named list column names: list(\"RSID\" = SNP, POS = \"BP\") output_format finished cleaned file saved? \"'csv' corresponds arrow::write_csv_arrow() 'parquet' corresponds arrow::write_parquet() 'hivestyle' corresponds arrow::write_dataset() split CHR output_dir filepath folder data stored. folder yet exist. CaseN manually input number cases ControlN manually input number controls N manually input sample size build sure genome build ('37' '38'), can used skip infer_build() speed computation default_build RSID exists, build inferred. Nonetheless, tidyGWAS applies filter incompatible alleles GRCh37/38. case, tidyGWAS needs decide reference genome compare alleles . indel_strategy indels kept removed? convert_p value used P-value rounded 0? repair_cols missing statistical columns repaired possible? logfile messages redirected logfile?","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/tidyGWAS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"dplyr::tibble()","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/tidyGWAS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"","code":"if (FALSE) { # \\dontrun{ tidyGWAS(tbl = \"my_dataframe\", logfile = \"true\", name = \"test_run\", outdir = \"gwas_sumstat_dir\") } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/update_rsid.html","id":null,"dir":"Reference","previous_headings":"","what":"Update rsIDs from dbSNP that have been merged into other RSIDs — update_rsid","title":"Update rsIDs from dbSNP that have been merged into other RSIDs — update_rsid","text":"Update rsIDs dbSNP merged RSIDs","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/update_rsid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update rsIDs from dbSNP that have been merged into other RSIDs — update_rsid","text":"","code":"update_rsid(tbl, filepaths, dbsnp_path)"},{"path":"http://arvidharder.com/tidyGWAS/reference/update_rsid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update rsIDs from dbSNP that have been merged into other RSIDs — update_rsid","text":"tbl dplyr::tibble() filepaths list filepaths, created setup_pipeline_paths() dbsnp_path filepath dbSNP155 directory","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/update_rsid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update rsIDs from dbSNP that have been merged into other RSIDs — update_rsid","text":"tbl","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/update_rsid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update rsIDs from dbSNP that have been merged into other RSIDs — update_rsid","text":"","code":"if (FALSE) { # \\dontrun{ update_rsid(sumstat, filepaths = setup_pipeline_paths(\"testing\"), dbsnp_path = \"~/dbSNP155\") } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that values in GWAS summary statistics columns are correct — validate_columns","title":"Check that values in GWAS summary statistics columns are correct — validate_columns","text":"validate_columns() remove rows, adds TRUE/FALSE flag specified column.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that values in GWAS summary statistics columns are correct — validate_columns","text":"","code":"validate_columns(   tbl,   col = c(\"B\", \"SE\", \"EAF\", \"N\", \"Z\", \"P\", \"POS\", \"CHR\", \"EffectAllele\", \"OtherAllele\",     \"CaseN\", \"ControlN\"),   convert_p = 2.225074e-308 )"},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that values in GWAS summary statistics columns are correct — validate_columns","text":"tbl dplyr::tibble() col column check values ? convert_p value used P-value rounded 0?","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that values in GWAS summary statistics columns are correct — validate_columns","text":"dplyr::tibble(), column added named invalid_col. validate \"B\" column, validate_columns add TRUE/FALSE column named invalid_B input tibble.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check that values in GWAS summary statistics columns are correct — validate_columns","text":"","code":"if (FALSE) { # \\dontrun{ gwas_file <- validate_columns(  tbl = gwas_file,  col = \"B\",  # if you want to keep 0 pvalues as 0.  convert_p = 0 ) dplyr::filter(gwas_file, invalid_P) } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_rsid.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"Validate format RSID column GWAS summary statistics file","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_rsid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"","code":"validate_rsid(tbl, outpath)"},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_rsid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"tbl data.frame character() vector outpath Filepath: write rows invalid RSID?","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_rsid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"tbl","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_rsid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"","code":"if (FALSE) { # \\dontrun{ validate_rsid(sumstat, \"~/invalid_rsid.parquet\") } # }"},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_sumstat.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"Validate statistics columns GWAS summary statistics file","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_sumstat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"","code":"validate_sumstat(tbl, remove_cols = c(\"\"), filter_func, convert_p, id)"},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_sumstat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"tbl dplyr::tibble() remove_cols Columns validated filter_func handles reporting writing removed files disk convert_p value used P-value rounded 0? id Used customize messages.","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_sumstat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"tbl","code":""},{"path":"http://arvidharder.com/tidyGWAS/reference/validate_sumstat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"","code":"if (FALSE) { # \\dontrun{ validate_sumstat(sumstat, remove_cols = \"EffectAllele\", convert_p = 0) } # }"},{"path":"http://arvidharder.com/tidyGWAS/news/index.html","id":"tidygwas-090","dir":"Changelog","previous_headings":"","what":"tidyGWAS 0.9.0","title":"tidyGWAS 0.9.0","text":"Major revision earlier versions. reference data format updated: Compression switched gzip snappy (better speed, less installation issues) GRCh37 GRCh38 merged single file, requiring one merge get CHR, POS RSID builds. introduced breaking changes 0.9 vs 0.8, speed ~100% ( 2.5 minutes instead ~5minutes). new reference data can found ","code":""}]
