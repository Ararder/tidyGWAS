[{"path":"https://ararder.github.io/tidyGWAS/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 tidyGWAS authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"tidyGWAS","text":"tidyGWAS yet CRAN. install, need use devtools::install_github() remotes::install_github() Secondly, need download reference data. tidyGWAS uses slightly edited version dbSNP v155, available .","code":"devtools::install_github(\"ararder/tidyGWAS\") remotes::install_github(\"ararder/tidyGWAS\") wget https://zenodo.org/records/14697504/files/dbSNP155.tar tar -xvf dbSNP155.tar"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"using-an-apptainer-or-docker-container-instead","dir":"Articles","previous_headings":"Installation","what":"Using an apptainer or docker container instead","title":"tidyGWAS","text":"can skip installation step using docker container docker apptainer.","code":"# using apptainer apptainer pull docker://arvhar/tidygwas:latest apptainer shell ~/tidygwas_latest.sif  # using docker  docker run arvhar/tidygwas:latest"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"quick-start","dir":"Articles","previous_headings":"","what":"Quick start","title":"tidyGWAS","text":"typical call tidyGWAS() look like. detailed explanation different arguments follows.","code":"# we setup a directory where we will store all summary statistics cleaned by tidyGWAS gwas_folder <- tempfile() # provide the filepath to the name of a directory that tidyGWAS will create. outdir <- paste0(gwas_folder, \"gwasName\")  cleaned <- tidyGWAS(   tbl = \"/filepath/to/sumstats\",    # we read in a tab-separated file, so provide tab as delimiter   delim = \"\\t\",   dbsnp_path = dsnp_path,   #    column_names = list(     \"CHR\" = \"CHROM\",     \"POS\" = \"BP\",     \"EffectAllele\" = \"A1\",     \"B\" = \"Effect\"   ),   # Number of samples are missing, so manually impute   CaseN = 54000,   ControlN = 73000,   logfile=TRUE,   output_dir = outdir   )"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"tutorial","dir":"Articles","previous_headings":"","what":"Tutorial","title":"tidyGWAS","text":"Provide tidyGWAS either -memory dplyr::tibble() filepath. filepath gzipped tsv file passed, along delim = \"\\t\". tidyGWAS uses arrow::read_delim_arrow() read files disk. trouble parsing file correctly, use another package data.table::fread() readr::read_table() first read memory, pass -memory data.frame tidyGWAS. dbsnp_path = dbsnp_path gives filepath reference data. output_dir = gives filepath output directory tidyGWAS create. directory exist yet - protect accidently overwriting files. argument passed output_dir, tidyGWAS create folder R tempdir, meaning cleaned summary statistics deleted R session ended.","code":"library(tidyGWAS) # we use the dummy version of dbSNP that comes with the package dbsnp_path <- system.file(\"extdata/dbSNP155\", package = \"tidyGWAS\")  # a dummy sumstats with 100 000 rows gwas <- system.file(\"extdata/sumstats.tsv.gz\", package = \"tidyGWAS\") # store the results in a temporary directory out <- tempfile()  tidyGWAS(   tbl = gwas,   delim = \"\\t\",   dbsnp_path = dbsnp_path,   output_dir = out ) #> Parsing input summary statistics... #>  #>  #> ── Running tidyGWAS 0.9.9.2 ──────────────────────────────────────────────────── #>  #> Starting at 2025-07-03 14:52:45.166791 #> with 100000 rows in input data.frame #> ℹ Saving output in folder: /tmp/RtmpCdYJNV/file1dd62620c8e0 #>  #>  #>  #> ── The detected format is \"fastGWA\"  #>  #> Was able to map 4 out of 13 columns to tidyGWAS columns #> ✔ CHR -> CHR #>  #> ✔ POS -> POS #>  #> ✔ P -> P #>  #> ✔ SE -> SE #>  #> ! extra column(s) \"RSID\", \"EffectAllele\", \"OtherAllele\", \"B\", \"EAF\", \"INFO\", \"CaseN\", and \"ControlN\" were not mapped to a tidyGWAS column #>  #>  #>  #> ── Checking that columns follow tidyGWAS format  #>  #> ✔ The following columns are used for further steps: CHR, POS, RSID, EffectAllele, OtherAllele, B, SE, EAF, INFO, P, CaseN, ControlN, and rowid #>  #>  #>  #> ── Checking for columns with all NA  #>  #> ✔ Found no columns with all NA #>  #> ℹ Found CaseN and ControlN, and no effective N: #> Calculating EffectiveN by `EffectiveN = 4 / (1 / ControlN + 1 / CaseN)` #>  #> ℹ Found CaseN and ControlN, Calculating N by `N = ControlN + CaseN` #>  #>  #>  #> ── 1) Scanning for indels ── #>  #>  #>  #> ✔ No rows contained missing values in EffectAllele and OtherAllele #>  #> 1. EffectAllele or OtherAllele, character length > 1: A vs AA #>  #> 2. EffectAllele or OtherAllele coded as 'D', 'I', or 'R' #>  #> ✔ Detected 0 rows as indels #>  #>  #>  #> ── 2) Scanning for rows with NA in critical columns ── #>  #>  #>  #> ✔ No rows contained missing values in CHR and POS #>  #>  #>  #> ── 3) Scanning for rows with duplications ── #>  #>  #>  #> ℹ Looking for duplications with columns: CHR, POS, EffectAllele, and OtherAllele #>  #> ✔ Found no duplications #>  #>  #>  #> ── 4) Validating columns  #>  #> ℹ The median value of B is -0.0012, which seems reasonable #>  #>  #>  #> ── All rows passed validation  #>  #>  #>  #> ── 5) Adding RSID based on CHR:POS. Adding dbSNP based QC flags  #>  #> ℹ Inferring build by matching 10000 rows to GRCh37 and GRCh38 #>  #> 99 snps matched GRCh38, 9998 for GRCh37, inferring build to be 37 #> ! Removed 21 rows with no dbSNP entry or with incompat alleles #>  #> /tmp/RtmpCdYJNV/file1dd62620c8e0/pipeline_info/removed_nodbsnp.parquet #>  #>  #> ── 6) Repairing missings statistics columns if possible ── #>  #>  #>  #> ℹ Z missing: Calculating Z using the formula:  Z = B / SE #>  #>  #>  #> ── Finished repair_stats:   #>  #> ℹ Added 1 new columns: Z #>  #>  #>  #> ── Listing final breakdown of removed rows:   #>  #> nodbsnp: 21 #>  #>  #>  #> ── Finished tidyGWAS ─────────────────────────────────────────────────────────── #>  #> ℹ A total of 21 rows were removed #>  #> ℹ Total running time: 3.7s #>  #> Saving metadata from analysis to /tmp/RtmpCdYJNV/file1dd62620c8e0/metadata.yaml #> # A tibble: 99,979 × 20 #>    CHR   POS_37 EffectAllele OtherAllele rowid     B        P     SE  INFO CaseN #>    <chr>  <int> <chr>        <chr>       <int> <dbl>    <dbl>  <dbl> <dbl> <int> #>  1 6     2.75e7 C            T           77548 0.212 4.83e-39 0.0162 0.99  53386 #>  2 6     2.81e7 T            C           36396 0.207 4.67e-38 0.016  1     53386 #>  3 6     2.75e7 C            T           77992 0.206 7.92e-38 0.016  0.993 53386 #>  4 6     2.78e7 T            C           67347 0.171 1.45e-32 0.0144 1     53386 #>  5 6     2.63e7 T            C            7577 0.191 8.94e-30 0.0168 0.996 53386 #>  6 6     3.08e7 G            A           26615 0.157 9.77e-28 0.0144 0.954 53386 #>  7 6     2.83e7 C            T           91092 0.116 4.33e-27 0.0108 1.01  53386 #>  8 6     2.64e7 C            T           84820 0.151 9.52e-27 0.0141 1     53386 #>  9 6     3.11e7 C            T           17683 0.143 1.54e-25 0.0137 1     53386 #> 10 6     3.03e7 A            G           71635 0.154 2.58e-25 0.0148 0.992 49683 #> # ℹ 99,969 more rows #> # ℹ 10 more variables: ControlN <int>, EAF <dbl>, EffectiveN <int>, N <int>, #> #   POS_38 <int>, RSID <chr>, REF_37 <chr>, REF_38 <chr>, multi_allelic <lgl>, #> #   Z <dbl>"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"output-files","dir":"Articles","previous_headings":"Tutorial","what":"Output files","title":"tidyGWAS","text":"tidyGWAS returns output directory. ’s lot files! Removed rows stored pipeline/removed_* metadata.yaml contains metadata execution raw contains summary statistics munging done. Useful reproduce, identify rows removed. tidyGWAS_hivestyle contains cleaned summary statistics, something called hivestyle partition, default. motivation detailed vignette. just want standard csv file, use output_format=\"csv\" output_format=\"parquet\" read cleaned summary statistics: df <- arrow::open_dataset(paste0(, \"/tidyGWAS_hivestyle\")) |> dplyr::collect()","code":"fs::dir_tree(out) #> /tmp/RtmpCdYJNV/file1dd62620c8e0 #> ├── metadata.yaml #> ├── pipeline_info #> │   ├── removed_nodbsnp.parquet #> │   └── removed_validate_chr_pos_path.parquet.parquet #> ├── raw #> │   └── sumstats.tsv.gz.parquet #> └── tidyGWAS_hivestyle #>     ├── CHR=1 #>     │   └── part-0.parquet #>     ├── CHR=10 #>     │   └── part-0.parquet #>     ├── CHR=11 #>     │   └── part-0.parquet #>     ├── CHR=12 #>     │   └── part-0.parquet #>     ├── CHR=13 #>     │   └── part-0.parquet #>     ├── CHR=14 #>     │   └── part-0.parquet #>     ├── CHR=15 #>     │   └── part-0.parquet #>     ├── CHR=16 #>     │   └── part-0.parquet #>     ├── CHR=17 #>     │   └── part-0.parquet #>     ├── CHR=18 #>     │   └── part-0.parquet #>     ├── CHR=19 #>     │   └── part-0.parquet #>     ├── CHR=2 #>     │   └── part-0.parquet #>     ├── CHR=20 #>     │   └── part-0.parquet #>     ├── CHR=21 #>     │   └── part-0.parquet #>     ├── CHR=22 #>     │   └── part-0.parquet #>     ├── CHR=3 #>     │   └── part-0.parquet #>     ├── CHR=4 #>     │   └── part-0.parquet #>     ├── CHR=5 #>     │   └── part-0.parquet #>     ├── CHR=6 #>     │   └── part-0.parquet #>     ├── CHR=7 #>     │   └── part-0.parquet #>     ├── CHR=8 #>     │   └── part-0.parquet #>     └── CHR=9 #>         └── part-0.parquet"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"setting-column-names","dir":"Articles","previous_headings":"Tutorial","what":"Setting column names","title":"tidyGWAS","text":"Almost certainly, summary statistics want clean column name example file . prevent parsing files wrong tidyGWAS() guess columns . Therefore, tidyGWAS requires colum names ’s native format mapping tidyGWAS column names column names input file. done using column_names argument, takes named list, names tidyGWAS columns values corresponding column input file.","code":"sumstats <- read.table(gwas, header=T) |> dplyr::tibble() head(sumstats) #> # A tibble: 6 × 13 #>     CHR      POS RSID       EffectAllele OtherAllele        B     SE   EAF  INFO #>   <int>    <int> <chr>      <chr>        <chr>          <dbl>  <dbl> <dbl> <dbl> #> 1     6 31819813 rs1839882… C            G           -0.00570 0.0292 0.975 0.936 #> 2    16 13991338 rs8044430  T            C           -0.0177  0.0092 0.641 0.951 #> 3     9 85016930 rs1114040… A            T           -0.00230 0.0185 0.916 0.701 #> 4    19 15743403 rs4807961  C            G            0.00240 0.0099 0.256 0.996 #> 5    18  5948313 rs948293   T            C            0.00170 0.0092 0.332 0.971 #> 6    13 47224772 rs837      G            A            0.0272  0.0086 0.447 1.01  #> # ℹ 4 more variables: P <dbl>, CaseN <int>, ControlN <int>, rowid <int> colnames(sumstats) #>  [1] \"CHR\"          \"POS\"          \"RSID\"         \"EffectAllele\" \"OtherAllele\"  #>  [6] \"B\"            \"SE\"           \"EAF\"          \"INFO\"         \"P\"            #> [11] \"CaseN\"        \"ControlN\"     \"rowid\" # what if the names were all wrong? sumstats_with_wrong_names <- dplyr::rename(   sumstats,    CHROM = CHR,    BP = POS,   ID = RSID,   A1 = EffectAllele,    A2 = OtherAllele,   EFFECT = B )  tidyGWAS(   tbl = sumstats_with_wrong_names,    dbsnp_path = dbsnp_path,   column_names = list(     CHR = \"CHROM\",     POS = \"BP\",     RSID = \"ID\",     EffectAllele = \"A1\",     OtherAllele = \"A2\",     B = \"EFFECT\"   )   )"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"the-tidygwas-columns","dir":"Articles","previous_headings":"Tutorial","what":"The tidyGWAS columns","title":"tidyGWAS","text":"tidyGWAS uses following column names: CHR POS RSID EffectAllele OtherAllele EAF B SE P CaseN ControlN N INFO Z Note: RSID column format CHR:BP:A1:A2, can still pass RSID column.","code":""},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"inputting-sample-size-columns","dir":"Articles","previous_headings":"Tutorial","what":"Inputting sample size columns","title":"tidyGWAS","text":"Often, sample size column missing summary statistics, provide manually. tidyGWAS three arguments can used manually set sample size, ’s missing original file: CaseN ControlN N","code":"cleaned <- tidyGWAS(   tbl = sumstats,    dbsnp_path = dbsnp_path,   # CaseN, ControlN and N can all be used to set sample size   CaseN = 400,   ControlN = 800,   N = 1200   )"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"reading-in-files","dir":"Articles","previous_headings":"Tutorial","what":"Reading in files","title":"tidyGWAS","text":"pass filepath tidyGWAS, attempt read file arrow::read_delim_arrow() default delimiter white space, read comma-separated files tab-separated files, can provide delim argument arrow::read_delim_arrow() ... ’s lot different field delimiters used wild, sometimes can struggle inputting correct delimiter. cases, ’s often much convenient use effective data.table::fread() readr::read_table() first read summary statistics memory passing tidyGWAS.","code":"cleaned <- tidyGWAS(   tbl = \"filepath/to/gwas/ondisk.csv\",   # here we specify the delimiter to for csv files   delim = \",\",   dbsnp_path = dbsnp_path, ) # use readr sumstats <- readr::read_table(\"path/to/sumstats.gz.vcf\") # or data.table sumstats <- data.table::fread(\"path/to/sumstats.gz.vcf\")  output <- \"my_gwas_dir\"  cleaned <- tidyGWAS(   tbl = sumstats,   dbsnp_path = dbsnp_path,   outdir = output )"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"hivestyle-partitioning","dir":"Articles","previous_headings":"","what":"Hivestyle-partitioning","title":"tidyGWAS","text":"default output format hivestyle format using .parquet files. See example motivation . essence, format significantly speed downstream applications meta-analysis, LD querying analyses.","code":""},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"variant-identity","dir":"Articles","previous_headings":"Hivestyle-partitioning","what":"Variant identity","title":"tidyGWAS","text":"TidyGWAS add following columns dealing variant ID, addition saving validating valid columns input file. CHR Chromosome. across builds POS_38, POS_37 genomic position GRCh38 GRCh37 RSID variant ID dbSNP REF_37, REF_38 reference genome allele GRCh38 GRCh37 multi_allelic TRUE/FALSE column flag rows multi-allelic summary statistics whether multiple alleles dbSNP. (TRUE corresponds multi allelic). rowid maps row back inputted summary statistics file raw, row can mapped back ’s original values. indel TRUE/FALSE whether variant type INsertion/DELetion valid columns input summary statistics file possible repair_stats() add statistics columns B, P, SE, Z, missing possible repair.","code":""},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"parallel-computation","dir":"Articles","previous_headings":"","what":"Parallel computation","title":"tidyGWAS","text":"tidyGWAS automatically detects number cores. cases, example running tidyGWAS HPC cluster, might need manually set number cores, can done using OMP_NUM_THREADS variable. larger number cores requested HPC job (example , “–cpus-per-task” flag)","code":"#SBATCH --mem=60gb #SBATCH --time=24:0:00 #SBATCH --cpus-per-task 8 export OMP_NUM_THREADS=8  outdir=$(pwd) gwas=$outdir/my_gwas.tsv.gz dbsnp_files=\"dbSNP155\" Rscript -e \"tidyGWAS(commandArgs(trailingOnly = TRUE)[1],  dbsnp_path = commandArgs(trailingOnly = TRUE)[2],outdir = commandArgs(trailingOnly = TRUE)[3], logfile=TRUE)\" $gwas $dbsnp_files $outdir"},{"path":"https://ararder.github.io/tidyGWAS/articles/tidyGWAS.html","id":"computational-cost-and-memory-usage","dir":"Articles","previous_headings":"","what":"Computational cost and memory usage","title":"tidyGWAS","text":"Memory use time scales size summary statistics. running tidyGWAS, ’s estimation. Especially, summary statistics missing CHR POS, tidyGWAS require additional memory. 1. 10 million rows ~ 5-15gb 2. 40 million rows 10-40gb 3. 60 million rows 65-85gb","code":""},{"path":"https://ararder.github.io/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"converting-dbsnp-to--parquet-files","dir":"Articles","previous_headings":"","what":"Converting dbSNP to .parquet files","title":"get-to-know-dbsnp","text":"dbSNP data accessed munged BSgenome package. Takes 10~30 minutes per chromosome, peak memory usage ~80gb chromosome 2","code":"library(arrow) library(BSgenome) library(glue)  chr <- commandArgs(trailingOnly = TRUE)[1] build <- commandArgs(trailingOnly = TRUE)[2]  if(build == \"37\") {   snps <- SNPlocs.Hsapiens.dbSNP155.GRCh37::SNPlocs.Hsapiens.dbSNP155.GRCh37   genome <- BSgenome.Hsapiens.1000genomes.hs37d5::BSgenome.Hsapiens.1000genomes.hs37d5   grch <- \"GRCh37\" } else if(build == \"38\") {    snps <- SNPlocs.Hsapiens.dbSNP155.GRCh38::SNPlocs.Hsapiens.dbSNP155.GRCh38   genome <- BSgenome.Hsapiens.NCBI.GRCh38::BSgenome.Hsapiens.NCBI.GRCh38   grch <- \"GRCh38\" } outpath <- glue(\"~/arvhar/snp_level_annotatations/dbSNP155/{grch}\")  # IUPAC ambuigity codes, to update FASTA files from ref genome updated <-   stringr::str_split(Biostrings::IUPAC_CODE_MAP, \"\") |>   purrr::map(\\(x) stringr::str_flatten(x, collapse=\",\")) |>   purrr::map_chr(stringr::str_c) |>   purrr::set_names(names(Biostrings::IUPAC_CODE_MAP))    print(glue(\"converting data for chr {chr}\"))  tictoc::tic(glue::glue(\"finished reading in chr: {chr}\")) all_snps <- snpsBySeqname(snps, seqnames = chr, genome = genome, drop.rs.prefix=TRUE) tictoc::toc()   dt <- data.table::as.data.table(all_snps) dt <- dplyr::mutate(dt, ref_allele = updated[ref_allele], alt_alleles = updated[alt_alleles]) dt <- tidyr::separate_longer_delim(dt, ref_allele, delim =\",\")  dt <- dplyr::select(dt, CHR = seqnames, POS =pos, RSID = RefSNP_id, REF = ref_allele, ALT = alt_alleles)  # storing as integer speeds up computation later on dt <- dplyr::mutate(dt, RSID = as.integer(stringr::str_sub(start = 3, RSID)))  print(glue(\"Writing data to {outpath}\")) write_dataset(dplyr::group_by(dt, CHR), outpath)"},{"path":"https://ararder.github.io/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"pruning-duplicates","dir":"Articles","previous_headings":"","what":"Pruning duplicates","title":"get-to-know-dbsnp","text":"","code":"remove_dups <- function(kk) {     start <- nrow(kk)      step1 <- distinct(kk, .keep_all=TRUE)     n_step1 <- nrow(step1)     cli::cli_alert(\"removed {start-n_step1} rows as pure duplicates\")      step2 <- mutate(step1, dup_rsid = duplicated(step1[,\"RSID\"]) | duplicated(step1[,\"RSID\"], fromLast = TRUE)) |>          filter(!dup_rsid)     step2$dup_rsid <- NULL     n_step2 <- nrow(step2)     cli::cli_alert(\"removed {n_step1-n_step2} rows with duplicated RSIDs\")       step3 <- distinct(arrange(step2, RSID), CHR, POS, .keep_all=TRUE)     n_step3 <- nrow(step3)     cli::cli_alert(\"removed {n_step2 - n_step3} rows with duplicated CHR-POS\")      cli::cli_alert_warning(\"removed a total of {start - n_step3} rows\")     step3     }  clean_dbsnp <- function(chr) {     tictoc::tic(glue::glue(\"time to clean {chr}\"))     df1 <- arrow::open_dataset(\"~/ki-pgi-storage/Data/downstreamGWAS/reference/dbSNP155/GRCh37\") |>          filter(CHR == chr) |>          dplyr::collect()      df1 <- remove_dups(df1)     n_df1 <- nrow(df1)      df2 <- arrow::open_dataset(\"~/ki-pgi-storage/Data/downstreamGWAS/reference/dbSNP155/GRCh38\") |>          filter(CHR == chr) |>          dplyr::collect()      df2 <- remove_dups(df2)     n_df2 <- nrow(df2)           ###################### MERGE ######################     out <- inner_join(df1, df2, by = \"RSID\", suffix = c(\"_37\", \"_38\"))          cli::cli_alert(\"removed {n_df2 - nrow(out)} rows from GRCh38, and {n_df1 - nrow(out)} from GRCH37 after merging across genome builds\")      final <- filter(out, CHR_37 == CHR_38) |>          rename(CHR = CHR_38)          cli::cli_alert(\"removed {nrow(out) - nrow(final)} rows with different chromosome numbers across genonme builds\")          final |>          select(-CHR_37) |>          relocate(CHR, POS_38, POS_37, RSID, REF_38, REF_37, ALT_38, ALT_37) |>          group_by(CHR) |>          arrow::write_dataset(\"dbSNP155_v2\")      tictoc::toc() }    tr <- c(1:22, \"X\", \"Y\", \"MT\") withr::local_message_sink(\"logfile.txt\") for(x in tr) {     clean_dbsnp(x) }"},{"path":"https://ararder.github.io/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"transforming-refsnp-merged-to-parquet","dir":"Articles","previous_headings":"Pruning duplicates","what":"Transforming refsnp-merged to parquet","title":"get-to-know-dbsnp","text":"","code":"library(arrow) library(tidyverse)  # wget https://ftp.ncbi.nlm.nih.gov/snp/latest_release/JSON/refsnp-merged.json.bz2 ref <- read_json_arrow(\"~/refsnp-merged.json.bz2\", col_select = c(\"refsnp_id\", \"merged_snapshot_data\"))  RSID = ref$merged_snapshot_data$merged_into test <- map_chr(ref$merged_snapshot_data$merged_into, \\(x) stringr::str_flatten(x))  old_RSID = ref$refsnp_id tmp = data.frame(old_RSID, test) tmp$old_RSID = as.integer(tmp$old_RSID) tmp$test = as.integer(tmp$test)   write_parquet(tmp, \"~/part0\", compression = \"gzip\")  # write out as parquet"},{"path":"https://ararder.github.io/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"noteworthy-aspects-of-dbsnp155","dir":"Articles","previous_headings":"","what":"Noteworthy aspects of dbSNP155","title":"get-to-know-dbsnp","text":"dbSNP version: 155 section work progress, summarises idiosyncracies dbSNP data.","code":""},{"path":"https://ararder.github.io/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"issue-1---same-chrpos-can-map-to-multiple-snps","dir":"Articles","previous_headings":"Noteworthy aspects of dbSNP155","what":"Issue 1) - same CHR:POS can map to multiple SNPs","title":"get-to-know-dbsnp","text":"particular example, three SNPs merged rs10157617. check history tab however, can see merge happened dbSNP 156. - issue yet fixed data tidyGWAS using.","code":""},{"path":"https://ararder.github.io/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"solution","dir":"Articles","previous_headings":"Noteworthy aspects of dbSNP155 > Issue 1) - same CHR:POS can map to multiple SNPs","what":"Solution","title":"get-to-know-dbsnp","text":"case CHR:POS maps multiple RSIDs, tidyGWAS selects RSID smallest rs number, mimic dbSNP performs merges.","code":"# on GRCh38 #  CHR        POS RSID         ref_allele alt_alleles #   <chr>    <int> <chr>        <chr>      <list>      # 1 1     39491595 rs10157617   T          <chr [2]>   # 2 1     39491595 rs1638449573 T          <chr [1]>   # 3 1     39491595 rs1638449625 T          <chr [1]>   # 4 1     39491595 rs1638449683 T          <chr [1]>"},{"path":"https://ararder.github.io/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"some-snps-only-have-chrpos-on-grch37","dir":"Articles","previous_headings":"Noteworthy aspects of dbSNP155 > Issue 1) - same CHR:POS can map to multiple SNPs","what":"2) Some SNPs only have CHR:POS on GRCh37","title":"get-to-know-dbsnp","text":"SNPs CHR POS GRCh37, yet mapped GRCh38. tidyGWAS() simply show rows CHR POS missing, CHR_37 POS_37 !","code":""},{"path":"https://ararder.github.io/tidyGWAS/articles/transforming_dbsnp_to_parquet.html","id":"some-rsids-map-to-multiple-chrpos","dir":"Articles","previous_headings":"Noteworthy aspects of dbSNP155 > Issue 1) - same CHR:POS can map to multiple SNPs","what":"3) some RSIDs map to multiple CHR:POS","title":"get-to-know-dbsnp","text":"See NCBI discussion","code":""},{"path":"https://ararder.github.io/tidyGWAS/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Arvid Harder. Maintainer.","code":""},{"path":"https://ararder.github.io/tidyGWAS/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Harder (2025). tidyGWAS: Quality control GWAS summary statistics minimal filtering. R package version 0.9.9.2, http://arvidharder.com/tidyGWAS/.","code":"@Manual{,   title = {tidyGWAS: Quality control for GWAS summary statistics with minimal filtering},   author = {Arvid Harder},   year = {2025},   note = {R package version 0.9.9.2},   url = {http://arvidharder.com/tidyGWAS/}, }"},{"path":"https://ararder.github.io/tidyGWAS/index.html","id":"tidygwas","dir":"","previous_headings":"","what":"Quality control for GWAS summary statistics with minimal filtering","title":"Quality control for GWAS summary statistics with minimal filtering","text":"Interested trying tidyGWAS ? Check get started page. Genome-wide summary statistics becoming staple many different genetics genomics analysis pipelines. Often, specific filters suggested pipelines can different, requiring pipeline step summary statistics “munged”. tidyGWAS aims provide standardized format pipeline specific munging done. mind, tidyGWAS conservative removing rows, default keeps indels multi-allelic variants. tidyGWAS following: Detection duplicated rows (based RSID_REF_ALT CHR_POS_REF_ALT) Standardized column names Automatic updating merged RSIDs Detection optional removal deletions/insertions (“indels”) Detection non rsID values RSID column, automatic parsing common CHR:POS CHR:POS:REF:ALT format Standardization CHR values (ex: “23” -> “X”, “chr1” -> “1”) Validation standard GWAS columns, B, SE, P, N, FREQ, Z, CaseN, ControlN, A1, A2 Extremely small pvalues default converted 2.225074e-308 (minimum pvalue R) Imputation missing columns: RSID CHR:POS CHR:POS RSID. B,SE, P, Z, N EAF missing possible Validation CHR:POS:RSID matching dbSNP v.155 Cleaned sumstats provided coordinates GRCh37 GRCh38, TRUE/FALSE flags indels variants multi-allelic dataset working standardized GWAS formats, ’ve found GRCh37 GRCh38 coordinates, standardized column names significantly speeds downstream analysis. computationally intensive part aligning summary statistics dbSNP 155 (> 940 million rows) GRCh37 GRCh38 (total 1.8 billion rows) implemented using Apache Arrow R implementation, allowing full function run <3 minutes, using less 16gb, ~7 million rows Macbook Pro M2.","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/check_rest_avail.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if API access is available for a GWAS catalog study — check_rest_avail","title":"Check if API access is available for a GWAS catalog study — check_rest_avail","text":"Check API access available GWAS catalog study","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/check_rest_avail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if API access is available for a GWAS catalog study — check_rest_avail","text":"","code":"check_rest_avail(study_id)"},{"path":"https://ararder.github.io/tidyGWAS/reference/check_rest_avail.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if API access is available for a GWAS catalog study — check_rest_avail","text":"study_id study accession ID, e.g. \"GCST000001\"","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/check_rest_avail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if API access is available for a GWAS catalog study — check_rest_avail","text":"TRUE REST API available study, FALSE otherwise","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/check_rest_avail.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if API access is available for a GWAS catalog study — check_rest_avail","text":"","code":"if (FALSE) { # \\dontrun{ #' check_rest_avail(\"GCST000001\") } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/create_lake.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a data lake in hivestyle format — create_lake","title":"Create a data lake in hivestyle format — create_lake","text":"Create data lake hivestyle format","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/create_lake.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a data lake in hivestyle format — create_lake","text":"","code":"create_lake(dir, lake)"},{"path":"https://ararder.github.io/tidyGWAS/reference/create_lake.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a data lake in hivestyle format — create_lake","text":"dir directory containing tidyGWAS cleaned summary statistics. directory contain tidyGWAS_hivestyle directory. lake directory create data lake .","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/create_lake.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a data lake in hivestyle format — create_lake","text":"","code":"if (FALSE) { # \\dontrun{ # create_lake(\"/path/to/dir\", \"/path/to/lake\") } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_duplicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Find all rows which are part of a set of duplicated rows — flag_duplicates","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"Many duplication tools base::duplicated() dplyr::distinct() identify rows duplications. often useful see rows part duplication set, just second row. creates new column: dup_rsid dup_chr_pos, T/F flag. Specifically, flags rows duplication pair, just first last duplicate row, making easy work rows part duplication","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_duplicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"","code":"flag_duplicates(   tbl,   column = c(\"rsid\", \"chr_pos\", \"chr_pos_ref_alt\", \"rsid_ref_alt\") )"},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_duplicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"tbl dplyr::tibble() column columns used form unique ID?","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_duplicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"tibble new column marking duplicates","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_duplicates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find all rows which are part of a set of duplicated rows — flag_duplicates","text":"","code":"if (FALSE) { # \\dontrun{  # will tag multi-allelics as duplications flag_duplicates(tbl, column = \"rsid\") flag_duplicates(tbl, column = \"chr_pos\") # if you are interested in rows that are variant duplications flag_duplicates(tbl, column = \"rsid_ref_alt\") flag_duplicates(tbl, column = \"chr_pos_ref_alt\")  } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_indels.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect ","title":"Detect ","text":"Detect \"indels\" GWAS summary statistics","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_indels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect ","text":"","code":"flag_indels(tbl)"},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_indels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect ","text":"tbl dplyr::tibble() columns EffectAllele OtherAllele","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_indels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect ","text":"dplyr::tibble() TRUE/FALSE column indel added, indel == TRUE corresponds row marked indel.","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_indels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect ","text":"","code":"if (FALSE) { # \\dontrun{ all_indels <-   flag_indels(tbl) |>   dplyr::filter(indels) } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_invalid_rsid.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"Detect entries valid rsID's GWAS summary statistics","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_invalid_rsid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"","code":"flag_invalid_rsid(tbl, regex = \"^[rR][sS]?\\\\d{1,10}$\")"},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_invalid_rsid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"tbl dplyr::tibble() column RSID. regex regex used detect non-RSIDs","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_invalid_rsid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"dplyr::tibble() column invalid_rsid","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/flag_invalid_rsid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect entries that are not valid rsID's in GWAS summary statistics — flag_invalid_rsid","text":"","code":"if (FALSE) { # \\dontrun{ flag_invalid_rsid(tbl) |> dplyr::filter(invalid_rsid) } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog.html","id":null,"dir":"Reference","previous_headings":"","what":"Download summary statistics from GWAS catalog — from_gwas_catalog","title":"Download summary statistics from GWAS catalog — from_gwas_catalog","text":"Download summary statistics GWAS catalog","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download summary statistics from GWAS catalog — from_gwas_catalog","text":"","code":"from_gwas_catalog(study_id, quiet = FALSE)"},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download summary statistics from GWAS catalog — from_gwas_catalog","text":"study_id single character string study ID, e.g. \"GCST90475332\" quiet TRUE/FALSE - controls progress bar downloading","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download summary statistics from GWAS catalog — from_gwas_catalog","text":"filepath downloaded summary statistics","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download summary statistics from GWAS catalog — from_gwas_catalog","text":"","code":"if (FALSE) { # \\dontrun{ from_gwas_catalog(\"GCST90475332\") } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog_region.html","id":null,"dir":"Reference","previous_headings":"","what":"Query a specific region of interest for a using a gwas catalog study_id — from_gwas_catalog_region","title":"Query a specific region of interest for a using a gwas catalog study_id — from_gwas_catalog_region","text":"Query specific region interest using gwas catalog study_id","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog_region.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query a specific region of interest for a using a gwas catalog study_id — from_gwas_catalog_region","text":"","code":"from_gwas_catalog_region(study_id, chr, start, end)"},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog_region.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query a specific region of interest for a using a gwas catalog study_id — from_gwas_catalog_region","text":"study_id study accession ID, e.g. \"GCST000001\" chr chromosome number, e.g. \"1\" - \"chr1\" start base pair start position, e.g. 1000000 end base pair end position, e.g. 2000000","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog_region.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query a specific region of interest for a using a gwas catalog study_id — from_gwas_catalog_region","text":"dplyr::tibble()","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/from_gwas_catalog_region.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query a specific region of interest for a using a gwas catalog study_id — from_gwas_catalog_region","text":"","code":"if (FALSE) { # \\dontrun{ #' get_gwas_catalog_region(\"GCST000001\", \"1\", 1000000, 2000000) } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/get_open_targets_cs.html","id":null,"dir":"Reference","previous_headings":"","what":"Query Open targets for all credible sets containing the variant — get_open_targets_cs","title":"Query Open targets for all credible sets containing the variant — get_open_targets_cs","text":"Query Open targets credible sets containing variant","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/get_open_targets_cs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query Open targets for all credible sets containing the variant — get_open_targets_cs","text":"","code":"get_open_targets_cs(   variant_id,   page_size = 500,   api_url = \"https://api.platform.opentargets.org/api/v4/graphql\" )"},{"path":"https://ararder.github.io/tidyGWAS/reference/get_open_targets_cs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query Open targets for all credible sets containing the variant — get_open_targets_cs","text":"variant_id open targets format chr_pos_ref_alt: 5_100_101_A_C page_size number results per page, default 500 api_url URL Open Targets GraphQL API, default","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/get_open_targets_cs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query Open targets for all credible sets containing the variant — get_open_targets_cs","text":"dplyr::tibble following columns: CHR: chromosome POS: position P: p-value REF: reference allele ALT: alternate allele description: trait description study_id: study ID","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/get_open_targets_cs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query Open targets for all credible sets containing the variant — get_open_targets_cs","text":"","code":"if (FALSE) { # \\dontrun{ get_open_targets_cs(\"7_140459051_C_G\") } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/infer_build.html","id":null,"dir":"Reference","previous_headings":"","what":"Infer what genome build a GWAS summary statistics file is on. — infer_build","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"Infer genome build GWAS summary statistics file .","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/infer_build.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"","code":"infer_build(tbl, dbsnp_path, n_snps = 10000)"},{"path":"https://ararder.github.io/tidyGWAS/reference/infer_build.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"tbl data.frame character() vector dbsnp_path filepath dbSNP155 directory n_snps number snps check CHR POS ","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/infer_build.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"either \"37\" \"38\"","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/infer_build.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Infer what genome build a GWAS summary statistics file is on. — infer_build","text":"","code":"if (FALSE) { # \\dontrun{ genome_build <- infer_build(gwas_sumstats) } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform meta-analysis of GWAS summary statistics datasets cleaned by tidyGWAS — meta_analyze","title":"Perform meta-analysis of GWAS summary statistics datasets cleaned by tidyGWAS — meta_analyze","text":"meta_analyze() : flip effect allele reference allele (using either GRCh37 GRCh38), control ref variant id constructed using columns EAF (allele frequency) INFO (imputation quality) weighted sample size, present CaseN, N, ControlN EffectiveN summed carried forward","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform meta-analysis of GWAS summary statistics datasets cleaned by tidyGWAS — meta_analyze","text":"","code":"meta_analyze(   dset,   by = c(\"CHR\", \"POS\", \"RSID\", \"EffectAllele\", \"OtherAllele\"),   method = c(\"ivw\"),   ref = c(\"REF_37\", \"REF_38\") )"},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform meta-analysis of GWAS summary statistics datasets cleaned by tidyGWAS — meta_analyze","text":"dset arrow::open_dataset() object character vector column names group . Default c(\"CHR\", \"POS\", \"RSID\", \"EffectAllele\", \"OtherAllele\") method method use performing meta-analysis. Currently, IVW (based standard errors) supported. ref either \"REF_37\" \"REF_38\", depending column want use standardize reference allele","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform meta-analysis of GWAS summary statistics datasets cleaned by tidyGWAS — meta_analyze","text":"dplyr::tibble()","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform meta-analysis of GWAS summary statistics datasets cleaned by tidyGWAS — meta_analyze","text":"","code":"if (FALSE) { # \\dontrun{ dset <- arrow::open_dataset(\"path_to/sumstats/\") res <- meta_analyze(dset) } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze_by_chrom.html","id":null,"dir":"Reference","previous_headings":"","what":"meta_analyze summary statistics, one chromosome at a time! This function is exposed to allow for testing using real data — meta_analyze_by_chrom","title":"meta_analyze summary statistics, one chromosome at a time! This function is exposed to allow for testing using real data — meta_analyze_by_chrom","text":"meta_analyze summary statistics, one chromosome time! function exposed allow testing using real data","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze_by_chrom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"meta_analyze summary statistics, one chromosome at a time! This function is exposed to allow for testing using real data — meta_analyze_by_chrom","text":"","code":"meta_analyze_by_chrom(dset, chrom, by, ref)"},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze_by_chrom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"meta_analyze summary statistics, one chromosome at a time! This function is exposed to allow for testing using real data — meta_analyze_by_chrom","text":"dset arrow::open_dataset() object chrom chromosome use meta-analysis character vector column names group . Default c(\"CHR\", \"POS\", \"RSID\", \"EffectAllele\", \"OtherAllele\") ref either \"REF_37\" \"REF_38\", depending column want use standardize reference allele","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze_by_chrom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"meta_analyze summary statistics, one chromosome at a time! This function is exposed to allow for testing using real data — meta_analyze_by_chrom","text":"dplyr::tibble()","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/meta_analyze_by_chrom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"meta_analyze summary statistics, one chromosome at a time! This function is exposed to allow for testing using real data — meta_analyze_by_chrom","text":"","code":"if (FALSE) { # \\dontrun{ meta_analyze_by_crom(dset, chrom = \"22\") } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_ids.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment a data.frame with information from dbSNP — repair_ids","title":"Augment a data.frame with information from dbSNP — repair_ids","text":"Augment data.frame information dbSNP","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_ids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment a data.frame with information from dbSNP — repair_ids","text":"","code":"repair_ids(   tbl,   repair = c(\"rsid\", \"pos\"),   build = c(\"NA\", \"37\", \"38\"),   dbsnp_path )"},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_ids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment a data.frame with information from dbSNP — repair_ids","text":"tbl dplyr::tibble() columns CHR, POS, EffectAllele, OtherAllele RSID, EffectAllele, OtherAllele2. repair \"rsid\" repair RSID, \"pos\" repair CHR POS build used repair = \"rsid\" specify genome build dbsnp_path path directory containing dbSNP dataset","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_ids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment a data.frame with information from dbSNP — repair_ids","text":"dplyr::tibble() added columns CHR, POS_37, POS_38 RSID, REF_37, ALT_37, REF_38, ALT_38, no_dbsnp_entry, incompat_alleles","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_ids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augment a data.frame with information from dbSNP — repair_ids","text":"","code":"if (FALSE) { # \\dontrun{ repair_ids(gwas_sumstats, repair = \"rsid\", build = \"38\", dbsnp_path = \"/path/to/dbsnp\") } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"repair_stats() collection functions can used infer missing columns GWAS summary statistics. functions based functionality found online.","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"","code":"repair_stats(   tbl,   dbsnp_path,   impute_freq = c(\"None\", \"EUR\", \"AMR\", \"AFR\", \"SAS\", \"EAS\"),   impute_freq_file = NULL,   impute_n = FALSE )"},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"tbl data.frame character() vector dbsnp_path filepath dbSNP155 directory impute_freq one c(\"None\", \"EUR\", \"AMR\", \"AFR\", \"SAS\", \"EAS\"). None, imputation done. Otherwise precomputed alleles frequence 1000KG, selected ancestry used impute_freq_file filepath .parquet file custom allele frequencies. file needs tabular dataframe columns RSID, EffectAllele, OtherAllele, EAF. EAF correspond frequency EffectAllele. impute_n N imputed missing?","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"tibble","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/repair_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repair statistics column in a GWAS summary statistics tibble — repair_stats","text":"","code":"if (FALSE) { # \\dontrun{ updated <- repair_stats(my_gwas) } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/strand_flip.html","id":null,"dir":"Reference","previous_headings":"","what":"Strand flip alleles — strand_flip","title":"Strand flip alleles — strand_flip","text":"Strand flip alleles","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/strand_flip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Strand flip alleles — strand_flip","text":"","code":"strand_flip(tbl)"},{"path":"https://ararder.github.io/tidyGWAS/reference/strand_flip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Strand flip alleles — strand_flip","text":"tbl dplyr::tibble() columns EffectAllele OtherAllele","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/strand_flip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Strand flip alleles — strand_flip","text":"dplyr::tibble() columns EffectAllele OtherAllele flipped","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/strand_flip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Strand flip alleles — strand_flip","text":"","code":"if (FALSE) { # \\dontrun{ tbl <- strand_flip(tbl) } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/tidyGWAS.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"tidyGWAS() performs set validations input colummns, repairs missing columns, can add missing CHR/POS RSID. addition, CHR POS standardised GRCh38, coordinates GRCh37 added well. Briefly, tidyGWAS() updates RSID possible using refsnp-merged file dbSNP. inputed column validated coerced correct type. statistis P, B missing, tidyGWAS() attempt impute possible using repair_stats() Standard column names assumed, inputting function. deliberate decision automatic parsing important column names can ambiguous example, sumstats, A1 referes effect allele, formats use A1 non-effect allele.","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/tidyGWAS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"","code":"tidyGWAS(   tbl,   dbsnp_path,   ...,   column_names = NULL,   output_format = c(\"hivestyle\", \"parquet\", \"csv\"),   output_dir = tempfile(),   CaseN = NULL,   ControlN = NULL,   N = NULL,   impute_freq = c(\"None\", \"EUR\", \"AMR\", \"AFR\", \"SAS\", \"EAS\"),   impute_freq_file = NULL,   impute_n = FALSE,   allow_duplications = FALSE,   build = c(\"NA\", \"37\", \"38\"),   default_build = c(\"37\", \"38\"),   indel_strategy = c(\"keep\", \"remove\"),   convert_p = 2.225074e-308,   repair_cols = TRUE,   logfile = FALSE )"},{"path":"https://ararder.github.io/tidyGWAS/reference/tidyGWAS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"tbl data.frame character() vector dbsnp_path filepath dbSNP155 directory ... pass additional arguments arrow::read_delim_arrow(), tbl filepath. column_names named list column names: list(RSID = \"SNP\", POS = \"BP\") output_format finished cleaned file saved? 'csv' corresponds arrow::write_csv_arrow() 'parquet' corresponds arrow::write_parquet() 'hivestyle' corresponds arrow::write_dataset() split CHR output_dir filepath folder tidyGWAS output stored. folder yet exist. Note default argument tempfile(), meaning tidyGWAS output saved default R sessions. CaseN manually input number cases ControlN manually input number controls N manually input sample size impute_freq one c(\"None\", \"EUR\", \"AMR\", \"AFR\", \"SAS\", \"EAS\"). None, imputation done. Otherwise precomputed alleles frequence 1000KG, selected ancestry used impute_freq_file filepath .parquet file custom allele frequencies. file needs tabular dataframe columns RSID, EffectAllele, OtherAllele, EAF. EAF correspond frequency EffectAllele. impute_n N imputed missing? allow_duplications duplicated variants allowed? Useful munged sumstats QTL sumstats build sure genome build ('37' '38'), can used skip infer_build() speed computation default_build RSID exists, build inferred. Nonetheless, tidyGWAS applies filter incompatible alleles GRCh37/38. case, tidyGWAS needs decide reference genome compare alleles . indel_strategy indels kept removed? convert_p value used P-value rounded 0? repair_cols missing statistical columns repaired possible? calls repair_stats() TRUE logfile messages redirected logfile?","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/tidyGWAS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"dplyr::tibble()","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/tidyGWAS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Execute validation and quality control of GWAS summmary statistics — tidyGWAS","text":"","code":"if (FALSE) { # \\dontrun{ tidyGWAS(tbl = \"my_dataframe\", logfile = \"true\", name = \"test_run\", outdir = \"gwas_sumstat_dir\") } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_rsid.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"Validate format RSID column GWAS summary statistics file","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_rsid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"","code":"validate_rsid(tbl, filepath)"},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_rsid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"tbl data.frame character() vector filepath filepath write removed rows","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_rsid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"tbl","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_rsid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate format of the RSID column in a GWAS summary statistics file — validate_rsid","text":"","code":"if (FALSE) { # \\dontrun{ validate_rsid(sumstat, \"~/invalid_rsid.parquet\") } # }"},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_sumstat.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"Validate statistics columns GWAS summary statistics file","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_sumstat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"","code":"validate_sumstat(tbl, remove_cols = c(\"\"), filter_func, convert_p)"},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_sumstat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"tbl dplyr::tibble() remove_cols Columns validated filter_func handles reporting writing removed files disk convert_p value used P-value rounded 0?","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_sumstat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"tbl","code":""},{"path":"https://ararder.github.io/tidyGWAS/reference/validate_sumstat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate statistics columns in a GWAS summary statistics file — validate_sumstat","text":"","code":"if (FALSE) { # \\dontrun{ validate_sumstat(sumstat, remove_cols = \"EffectAllele\", convert_p = 0) } # }"},{"path":"https://ararder.github.io/tidyGWAS/news/index.html","id":"tidygwas-0992","dir":"Changelog","previous_headings":"","what":"tidyGWAS 0.9.9.2","title":"tidyGWAS 0.9.9.2","text":"Version bumping. 1.0 come manuscript accepted. Updates: 1. Added experimental support automatic column name guessing 2. Added experimental support downloading cleaning files directly GWAS catalog, using study_id","code":""},{"path":"https://ararder.github.io/tidyGWAS/news/index.html","id":"tidygwas-099","dir":"Changelog","previous_headings":"","what":"tidyGWAS 0.9.9","title":"tidyGWAS 0.9.9","text":"Added reference allele frequencies dbSNP155 reference data zenodo. Added options impute allele frequenecy reference data.","code":""},{"path":"https://ararder.github.io/tidyGWAS/news/index.html","id":"tidygwas-097","dir":"Changelog","previous_headings":"","what":"tidyGWAS 0.9.7","title":"tidyGWAS 0.9.7","text":"added functionality QTL summary statistics providing option remove duplicated variants. addition, added option provide custom reference file allele frequency, impute allele frequency reference file allele frequency missing. Added option impute N using SE allele frequency.","code":""},{"path":"https://ararder.github.io/tidyGWAS/news/index.html","id":"tidygwas-096","dir":"Changelog","previous_headings":"","what":"tidyGWAS 0.9.6","title":"tidyGWAS 0.9.6","text":"Added values tidyGWAS detects correct columns: 24 -> “Y” 25 -> “XY” 26 -> “MT”","code":""},{"path":"https://ararder.github.io/tidyGWAS/news/index.html","id":"tidygwas-090","dir":"Changelog","previous_headings":"","what":"tidyGWAS 0.9.0","title":"tidyGWAS 0.9.0","text":"Major revision earlier versions. reference data format updated: Compression switched gzip snappy (better speed, less installation issues) GRCh37 GRCh38 merged single file, requiring one merge get CHR, POS RSID builds. introduced breaking changes 0.9 vs 0.8, speed ~100% ( 2.5 minutes instead ~5minutes). new reference data can found ","code":""}]
